import sys
import subprocess
import os
import re
from datetime import datetime
import hashlib  # í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
from typing import TypedDict, List, Dict
import io
from contextlib import redirect_stdout, redirect_stderr

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ë° ì„¤ì¹˜
required_packages = {
    "google.generativeai": "google-generativeai",
    "faiss": "faiss-cpu",
    "numpy": "numpy",
    "dotenv": "python-dotenv",
    "sklearn": "scikit-learn",
    "langgraph": "langgraph",
    "matplotlib": "matplotlib",
    "seaborn": "seaborn",
    "pandas": "pandas",
    "PIL": "Pillow",
}

for lib, package in required_packages.items():
    try:
        __import__(lib.split(".")[0])
    except ImportError:
        print(f"{package} ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        except Exception as e:
            print(
                f"ì˜¤ë¥˜: {package} ì„¤ì¹˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install {package}"
            )
            sys.exit(1)

import tkinter as tk
from tkinter import messagebox, simpledialog, scrolledtext
import json
import numpy as np
import faiss
import google.generativeai
from google import genai
from dotenv import load_dotenv
from sklearn.cluster import KMeans
from google.genai import types
from langgraph.graph import StateGraph, END
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib.font_manager as fm

import threading
import queue


# ì½˜ì†” ë¡œê·¸ ìˆ˜ì§‘ì„ ìœ„í•œ í´ë˜ìŠ¤
class ConsoleLogger:
    def __init__(self):
        self.logs = []
        self.current_node = None
        self.node_logs = {}
        self.start_time = None
        self.node_start_times = {}

    def start_logging(self, session_id):
        """ë¡œê¹… ì„¸ì…˜ ì‹œì‘"""
        self.session_id = session_id
        self.start_time = datetime.now()
        self.logs = []
        self.node_logs = {}
        self.add_log("SYSTEM", f"=== ë³´ê³ ì„œ ìƒì„± ì„¸ì…˜ ì‹œì‘ (ID: {session_id}) ===")

    def set_current_node(self, node_name):
        """í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œ ì„¤ì •"""
        if self.current_node and self.current_node in self.node_start_times:
            # ì´ì „ ë…¸ë“œ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
            duration = (
                datetime.now() - self.node_start_times[self.current_node]
            ).total_seconds()
            self.add_log(
                "SYSTEM",
                f"ë…¸ë“œ '{self.current_node}' ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ)",
            )

        self.current_node = node_name
        self.node_start_times[node_name] = datetime.now()
        self.add_log("SYSTEM", f">>> ë…¸ë“œ '{node_name}' ì‹œì‘")

    def add_log(self, level, message):
        """ë¡œê·¸ ë©”ì‹œì§€ ì¶”ê°€"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = {
            "timestamp": timestamp,
            "level": level,
            "node": self.current_node,
            "message": message,
        }
        self.logs.append(log_entry)

        # ë…¸ë“œë³„ ë¡œê·¸ ë¶„ë¥˜
        if self.current_node:
            if self.current_node not in self.node_logs:
                self.node_logs[self.current_node] = []
            self.node_logs[self.current_node].append(log_entry)

        # ì½˜ì†”ì—ë„ ì¶œë ¥
        print(f"[{timestamp}] {level}: {message}")

    def save_logs(self, output_dir="."):
        """ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not self.logs:
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ì „ì²´ ë¡œê·¸ ì €ì¥
        full_log_path = os.path.join(output_dir, f"pipeline_log_{timestamp}.md")
        with open(full_log_path, "w", encoding="utf-8") as f:
            f.write(f"# ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œê·¸\n\n")
            f.write(f"**ì„¸ì…˜ ID**: {self.session_id}\n")
            f.write(f"**ì‹œì‘ ì‹œê°„**: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**ì¢…ë£Œ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(
                f"**ì´ ì†Œìš” ì‹œê°„**: {(datetime.now() - self.start_time).total_seconds():.2f}ì´ˆ\n\n"
            )

            f.write("## ì „ì²´ ì‹¤í–‰ ë¡œê·¸\n\n")
            for log in self.logs:
                node_info = f"[{log['node']}] " if log["node"] else ""
                f.write(
                    f"`{log['timestamp']}` **{log['level']}**: {node_info}{log['message']}\n\n"
                )

        # ë…¸ë“œë³„ ë¡œê·¸ ì €ì¥
        for node_name, node_logs in self.node_logs.items():
            node_log_path = os.path.join(
                output_dir, f"node_{node_name}_log_{timestamp}.md"
            )
            with open(node_log_path, "w", encoding="utf-8") as f:
                f.write(f"# ë…¸ë“œ '{node_name}' ì‹¤í–‰ ë¡œê·¸\n\n")
                f.write(f"**ì„¸ì…˜ ID**: {self.session_id}\n")
                if node_name in self.node_start_times:
                    start_time = self.node_start_times[node_name]
                    f.write(
                        f"**ì‹œì‘ ì‹œê°„**: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                    )
                f.write(f"**ë¡œê·¸ ìˆ˜**: {len(node_logs)}ê°œ\n\n")

                for log in node_logs:
                    f.write(
                        f"`{log['timestamp']}` **{log['level']}**: {log['message']}\n\n"
                    )

        self.add_log("SYSTEM", f"ë¡œê·¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {full_log_path}")
        return full_log_path, [
            os.path.join(output_dir, f"node_{node}_log_{timestamp}.md")
            for node in self.node_logs.keys()
        ]


# ê²°ê³¼ ì‹œê°í™” í´ë˜ìŠ¤
class ReportAnalyzer:
    def __init__(self):
        # matplotlib ë°±ì—”ë“œë¥¼ Aggë¡œ ì„¤ì • (GUI ì—†ì´ ì´ë¯¸ì§€ë§Œ ìƒì„±)
        import matplotlib

        matplotlib.use("Agg")

        # seaborn ìŠ¤íƒ€ì¼ì„ ë¨¼ì € ì„¤ì • (ì´í›„ í°íŠ¸ ì„¤ì •ì´ ë®ì–´ì“°ì§€ ì•Šë„ë¡)
        sns.set_style("whitegrid")

        # í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
        self._setup_korean_font()
        # unicode_minusëŠ” í°íŠ¸ ì„¤ì • í›„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ì£¼ëŠ” ê²ƒì´ ì•ˆì „
        plt.rcParams["axes.unicode_minus"] = False

    def _setup_korean_font(self):
        """í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•˜ê³ , ì‹¤íŒ¨ ì‹œ ì˜ì–´ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."""
        import platform
        import warnings

        if platform.system() != "Windows":
            print("âš ï¸ Windows í™˜ê²½ì´ ì•„ë‹ˆë¯€ë¡œ ì˜ì–´ ë ˆì´ë¸”ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            self._fallback_to_english()
            return

        font_name = "Malgun Gothic"
        try:
            # ì „ì—­ í°íŠ¸ ì„¤ì •
            plt.rc("font", family=font_name)
            plt.rcParams["axes.unicode_minus"] = False
            print(f"âœ… í•œê¸€ í°íŠ¸ '{font_name}' ì„¤ì • ì™„ë£Œ.")
            self.use_english_labels = False
        except Exception as e:
            print(f"âŒ '{font_name}' í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}. ì˜ì–´ ë ˆì´ë¸”ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            self._fallback_to_english()

        # ê²½ê³  ë©”ì‹œì§€ ê´€ë¦¬
        if not self.use_english_labels:
            warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

    def _fallback_to_english(self):
        """ì˜ì–´ ë ˆì´ë¸”ë¡œ í´ë°±"""
        plt.rcParams["font.family"] = ["DejaVu Sans", "Arial", "sans-serif"]
        print("âš ï¸ ì˜ì–´ ë ˆì´ë¸”ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        self.use_english_labels = True

    def _verify_font_before_plotting(self):
        """ì‹œê°í™” ìƒì„± ì „ í°íŠ¸ ì„¤ì • ì¬ê²€ì¦"""
        import matplotlib.font_manager as fm

        current_font = plt.rcParams["font.family"]
        print(f"ğŸ“Š ì‹œê°í™” ìƒì„± ì „ í°íŠ¸ ê²€ì¦: {current_font}")

        # í•œê¸€ í°íŠ¸ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ë§Œ ì‹¤ì œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œì§€ ì¬í™•ì¸
        if not self.use_english_labels:
            try:
                # ê°„ë‹¨í•œ í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ í…ŒìŠ¤íŠ¸
                fig, ax = plt.subplots(figsize=(1, 1))
                text = ax.text(0.5, 0.5, "í…ŒìŠ¤íŠ¸", fontsize=10)

                # í…ìŠ¤íŠ¸ ë Œë”ë§ í›„ í°íŠ¸ í™•ì¸
                renderer = fig.canvas.get_renderer()
                if hasattr(text, "_get_layout"):
                    layout = text._get_layout(renderer)

                plt.close(fig)
                print("   âœ… í•œê¸€ í°íŠ¸ ê²€ì¦ í†µê³¼")

            except Exception as e:
                print(f"   âŒ í•œê¸€ í°íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
                print("   ğŸ”„ ì˜ì–´ ë ˆì´ë¸”ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                self._fallback_to_english()
        else:
            print("   â„¹ï¸ ì˜ì–´ ë ˆì´ë¸” ëª¨ë“œ ì‚¬ìš© ì¤‘")

    def create_visualization_dashboard(self, logger, final_state, output_dir="."):
        """ì¢…í•© ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        try:
            # ì‹œê°í™” ìƒì„± ì „ í°íŠ¸ ì¬ê²€ì¦
            self._verify_font_before_plotting()

            # ë°ì´í„° ìˆ˜ì§‘
            analytics_data = self._collect_analytics_data(logger, final_state)

            # ëŒ€ì‹œë³´ë“œ ìƒì„±
            fig = plt.figure(figsize=(20, 15))

            if self.use_english_labels:
                dashboard_title = "RAG Report Generation Pipeline Analysis Dashboard"
            else:
                dashboard_title = "RAG ë¦¬í¬íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"

            fig.suptitle(
                dashboard_title,
                fontsize=20,
                fontweight="bold",
            )

            # 1. ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒí™© (2x3 ê·¸ë¦¬ë“œì˜ ì²« ë²ˆì§¸)
            ax1 = plt.subplot(2, 3, 1)
            self._plot_workflow_progress(ax1, analytics_data)

            # 2. ì‘ì—…ë³„ ì†Œìš”ì‹œê°„ (2x3 ê·¸ë¦¬ë“œì˜ ë‘ ë²ˆì§¸)
            ax2 = plt.subplot(2, 3, 2)
            self._plot_execution_times(ax2, analytics_data)

            # 3. ì°¸ê³ ë¬¸í—Œ í†µê³„ (2x3 ê·¸ë¦¬ë“œì˜ ì„¸ ë²ˆì§¸)
            ax3 = plt.subplot(2, 3, 3)
            self._plot_reference_stats(ax3, analytics_data)

            # 4. í¸ì§‘ì¥ ê²€í†  ê²°ê³¼ (2x3 ê·¸ë¦¬ë“œì˜ ë„¤ ë²ˆì§¸)
            ax4 = plt.subplot(2, 3, 4)
            self._plot_editorial_review(ax4, analytics_data)

            # 5. ë³´ê³ ì„œ í’ˆì§ˆ ì§€í‘œ (2x3 ê·¸ë¦¬ë“œì˜ ë‹¤ì„¯ ë²ˆì§¸)
            ax5 = plt.subplot(2, 3, 5)
            self._plot_quality_metrics(ax5, analytics_data)

            # 6. ë¡œê·¸ ë ˆë²¨ ë¶„í¬ (2x3 ê·¸ë¦¬ë“œì˜ ì—¬ì„¯ ë²ˆì§¸)
            ax6 = plt.subplot(2, 3, 6)
            self._plot_log_distribution(ax6, analytics_data)

            plt.tight_layout()

            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            dashboard_path = os.path.join(output_dir, f"dashboard_{timestamp}.png")
            plt.savefig(dashboard_path, dpi=300, bbox_inches="tight")

            # ê°œë³„ ì‹œê°í™”ë„ ì €ì¥
            self._save_individual_plots(analytics_data, output_dir, timestamp)

            print(f"ğŸ“Š ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ì €ì¥ ì™„ë£Œ: {dashboard_path}")
            return dashboard_path

        except Exception as e:
            print(f"âŒ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _collect_analytics_data(self, logger, final_state):
        """ë¶„ì„ìš© ë°ì´í„° ìˆ˜ì§‘"""
        data = {
            "total_duration": 0,
            "node_durations": {},
            "log_counts": {},
            "reference_stats": {},
            "editorial_reviews": [],
            "quality_metrics": {},
            "workflow_progress": [],
        }

        # ì´ ì†Œìš”ì‹œê°„ ê³„ì‚°
        if logger.start_time:
            data["total_duration"] = (
                datetime.now() - logger.start_time
            ).total_seconds()

        # ë…¸ë“œë³„ ì†Œìš”ì‹œê°„ ê³„ì‚°
        for node_name, start_time in logger.node_start_times.items():
            # ê° ë…¸ë“œì˜ ì™„ë£Œ ì‹œê°„ì„ ë¡œê·¸ì—ì„œ ì°¾ê¸°
            node_logs = logger.node_logs.get(node_name, [])
            if node_logs:
                # ë§ˆì§€ë§‰ ë¡œê·¸ ì‹œê°„ì„ ì™„ë£Œ ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©
                last_log = node_logs[-1]
                last_time = datetime.strptime(last_log["timestamp"], "%H:%M:%S")
                start_time_only = start_time.replace(
                    year=last_time.year, month=last_time.month, day=last_time.day
                )
                duration = (last_time - start_time_only).total_seconds()
                data["node_durations"][node_name] = max(duration, 0)

        # ë¡œê·¸ ë ˆë²¨ë³„ ì¹´ìš´íŠ¸
        for log in logger.logs:
            level = log["level"]
            data["log_counts"][level] = data["log_counts"].get(level, 0) + 1

        # ì°¸ê³ ë¬¸í—Œ í†µê³„ (final_stateì—ì„œ ì¶”ì¶œ)
        if final_state:
            final_report = final_state.get("final_report_with_refs", "")
            data["reference_stats"] = {
                "total_references": final_report.count("[^") if final_report else 0,
                "total_words": len(final_report.split()) if final_report else 0,
                "total_chars": len(final_report) if final_report else 0,
            }

            # í¸ì§‘ì¥ ê²€í†  ê²°ê³¼
            review_history = final_state.get("review_history", [])
            for review in review_history:
                result = review.get("result", {})
                data["editorial_reviews"].append(
                    {
                        "attempt": review.get("attempt", 0),
                        "passed": result.get("review_passed", True),
                        "sections_to_improve": len(
                            result.get("sections_to_improve", [])
                        ),
                    }
                )

        # ì›Œí¬í”Œë¡œìš° ì§„í–‰ìƒí™©
        workflow_nodes = [
            "generate_outline",
            "generate_draft",
            "editorial_review",
            "regenerate_sections",
            "final_formatting",
            "finalize_and_save",
        ]
        for i, node in enumerate(workflow_nodes):
            completed = node in logger.node_logs
            data["workflow_progress"].append(
                {
                    "node": node,
                    "step": i + 1,
                    "completed": completed,
                    "duration": data["node_durations"].get(node, 0),
                }
            )

        return data

    def _plot_workflow_progress(self, ax, data):
        """ì›Œí¬í”Œë¡œìš° ì§„í–‰ìƒí™© ì‹œê°í™”"""
        progress_data = data["workflow_progress"]
        nodes = [p["node"] for p in progress_data]
        completed = [p["completed"] for p in progress_data]

        # ë…¸ë“œ ì´ë¦„ í•œê¸€í™”/ì˜ì–´í™”
        if self.use_english_labels:
            node_names = {
                "generate_outline": "Generate Outline",
                "generate_draft": "Generate Draft",
                "editorial_review": "Editorial Review",
                "regenerate_sections": "Regenerate Sections",
                "final_formatting": "Final Formatting",
                "finalize_and_save": "Finalize & Save",
            }
            xlabel = "Completion Status"
            title = "Workflow Progress"
            complete_label = "Done"
            waiting_label = "Waiting"
        else:
            node_names = {
                "generate_outline": "ê°œìš”ìƒì„±",
                "generate_draft": "ì´ˆì•ˆìƒì„±",
                "editorial_review": "í¸ì§‘ê²€í† ",
                "regenerate_sections": "ì„¹ì…˜ì¬ì‘ì„±",
                "final_formatting": "ì„œì‹ì •ë¦¬",
                "finalize_and_save": "ìµœì¢…ì €ì¥",
            }
            xlabel = "ì™„ë£Œ ìƒíƒœ"
            title = "ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒí™©"
            complete_label = "ì™„ë£Œ"
            waiting_label = "ëŒ€ê¸°"

        display_nodes = [node_names.get(node, node) for node in nodes]
        colors = ["#4CAF50" if c else "#FFC107" for c in completed]

        bars = ax.barh(display_nodes, [1] * len(display_nodes), color=colors, alpha=0.8)
        ax.set_xlabel(xlabel)
        ax.set_title(title, fontweight="bold")
        ax.set_xlim(0, 1)

        # ì™„ë£Œ/ë¯¸ì™„ë£Œ ë ˆì´ë¸” ì¶”ê°€
        for i, (bar, comp) in enumerate(zip(bars, completed)):
            label = complete_label if comp else waiting_label
            ax.text(0.5, i, label, ha="center", va="center", fontweight="bold")

    def _plot_execution_times(self, ax, data):
        """ì‘ì—…ë³„ ì†Œìš”ì‹œê°„ ì‹œê°í™”"""
        node_durations = data["node_durations"]

        if self.use_english_labels:
            no_data_text = "No execution time data"
            title = "Execution Times by Task"
            ylabel = "Duration (seconds)"
            node_names = {
                "generate_outline": "Generate Outline",
                "generate_draft": "Generate Draft",
                "editorial_review": "Editorial Review",
                "regenerate_sections": "Regenerate Sections",
                "final_formatting": "Final Formatting",
                "finalize_and_save": "Finalize & Save",
            }
        else:
            no_data_text = "ì†Œìš”ì‹œê°„ ë°ì´í„° ì—†ìŒ"
            title = "ì‘ì—…ë³„ ì†Œìš”ì‹œê°„"
            ylabel = "ì†Œìš”ì‹œê°„ (ì´ˆ)"
            node_names = {
                "generate_outline": "ê°œìš”ìƒì„±",
                "generate_draft": "ì´ˆì•ˆìƒì„±",
                "editorial_review": "í¸ì§‘ê²€í† ",
                "regenerate_sections": "ì„¹ì…˜ì¬ì‘ì„±",
                "final_formatting": "ì„œì‹ì •ë¦¬",
                "finalize_and_save": "ìµœì¢…ì €ì¥",
            }

        if not node_durations:
            ax.text(
                0.5,
                0.5,
                no_data_text,
                ha="center",
                va="center",
                transform=ax.transAxes,
            )
            ax.set_title(title, fontweight="bold")
            return

        display_nodes = [node_names.get(node, node) for node in node_durations.keys()]
        times = list(node_durations.values())

        bars = ax.bar(display_nodes, times, color="#2196F3", alpha=0.8)
        ax.set_ylabel(ylabel)
        ax.set_title(title, fontweight="bold")
        ax.tick_params(axis="x", rotation=45)

        # ì‹œê°„ ë ˆì´ë¸” ì¶”ê°€
        for bar, time in zip(bars, times):
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height,
                f"{time:.1f}s",
                ha="center",
                va="bottom",
            )

    def _plot_reference_stats(self, ax, data):
        """ì°¸ê³ ë¬¸í—Œ í†µê³„ ì‹œê°í™”"""
        ref_stats = data["reference_stats"]

        if self.use_english_labels:
            metrics = ["References", "Total Words", "Total Characters"]
            title = "Report Statistics"
            ylabel = "Quantity"
        else:
            metrics = ["ì°¸ê³ ë¬¸í—Œ ìˆ˜", "ì´ ë‹¨ì–´ ìˆ˜", "ì´ ë¬¸ì ìˆ˜"]
            title = "ë³´ê³ ì„œ í†µê³„"
            ylabel = "ìˆ˜ëŸ‰"

        values = [
            ref_stats.get("total_references", 0),
            ref_stats.get("total_words", 0) // 100,  # 100ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤ì¼€ì¼ ì¡°ì •
            ref_stats.get("total_chars", 0) // 1000,  # 1000ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤ì¼€ì¼ ì¡°ì •
        ]

        bars = ax.bar(
            metrics, values, color=["#FF9800", "#4CAF50", "#9C27B0"], alpha=0.8
        )
        ax.set_title(title, fontweight="bold")
        ax.set_ylabel(ylabel)

        # ê°’ ë ˆì´ë¸” ì¶”ê°€
        for bar, value, original in zip(
            bars,
            values,
            [
                ref_stats.get("total_references", 0),
                ref_stats.get("total_words", 0),
                ref_stats.get("total_chars", 0),
            ],
        ):
            height = bar.get_height()
            if bar.get_x() == 0:  # ì°¸ê³ ë¬¸í—Œ ìˆ˜
                label = f"{original}"
            elif bar.get_x() == bars[1].get_x():  # ë‹¨ì–´ ìˆ˜
                label = f"{original:,}"
            else:  # ë¬¸ì ìˆ˜
                label = f"{original:,}"
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height,
                label,
                ha="center",
                va="bottom",
            )

    def _plot_editorial_review(self, ax, data):
        """í¸ì§‘ì¥ ê²€í†  ê²°ê³¼ ì‹œê°í™”"""
        reviews = data["editorial_reviews"]

        if self.use_english_labels:
            no_data_text = "No editorial review data"
            title = "Editorial Review Results"
            ylabel = "Review Result"
            attempt_prefix = "Attempt"
            pass_label = "Passed"
            fail_label = "Needs Improvement"
        else:
            no_data_text = "í¸ì§‘ì¥ ê²€í†  ë°ì´í„° ì—†ìŒ"
            title = "í¸ì§‘ì¥ ê²€í†  ê²°ê³¼"
            ylabel = "ê²€í†  ê²°ê³¼"
            attempt_prefix = "ì‹œë„"
            pass_label = "í†µê³¼"
            fail_label = "ê°œì„ í•„ìš”"

        if not reviews:
            ax.text(
                0.5,
                0.5,
                no_data_text,
                ha="center",
                va="center",
                transform=ax.transAxes,
            )
            ax.set_title(title, fontweight="bold")
            return

        attempts = [r["attempt"] for r in reviews]
        passed = [r["passed"] for r in reviews]
        colors = ["#4CAF50" if p else "#F44336" for p in passed]

        bars = ax.bar(
            [f"{attempt_prefix} {a}" for a in attempts],
            [1] * len(attempts),
            color=colors,
            alpha=0.8,
        )
        ax.set_ylabel(ylabel)
        ax.set_title(title, fontweight="bold")
        ax.set_ylim(0, 1.2)

        # ê²°ê³¼ ë ˆì´ë¸” ì¶”ê°€
        for bar, p in zip(bars, passed):
            label = pass_label if p else fail_label
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                0.5,
                label,
                ha="center",
                va="center",
                fontweight="bold",
            )

    def _plot_quality_metrics(self, ax, data):
        """ë³´ê³ ì„œ í’ˆì§ˆ ì§€í‘œ ì‹œê°í™”"""
        ref_stats = data["reference_stats"]

        # í’ˆì§ˆ ì§€í‘œ ê³„ì‚° (ì„ì˜ì˜ ê¸°ì¤€)
        total_words = ref_stats.get("total_words", 0)
        total_refs = ref_stats.get("total_references", 0)

        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100 ìŠ¤ì¼€ì¼)
        word_score = min(total_words / 3000 * 100, 100)  # 3000ë‹¨ì–´ ê¸°ì¤€
        ref_score = min(total_refs / 50 * 100, 100)  # 50ê°œ ì°¸ê³ ë¬¸í—Œ ê¸°ì¤€
        overall_score = (word_score + ref_score) / 2

        if self.use_english_labels:
            metrics = ["Content Richness", "Reference Completeness", "Overall Quality"]
            title = "Report Quality Metrics"
            ylabel = "Quality Score"
        else:
            metrics = ["ë‚´ìš© í’ë¶€ë„", "ì°¸ê³ ë¬¸í—Œ ì¶©ì‹¤ë„", "ì „ì²´ í’ˆì§ˆ"]
            title = "ë³´ê³ ì„œ í’ˆì§ˆ ì§€í‘œ"
            ylabel = "í’ˆì§ˆ ì ìˆ˜"

        scores = [word_score, ref_score, overall_score]
        colors = [
            "#4CAF50" if s >= 80 else "#FF9800" if s >= 60 else "#F44336"
            for s in scores
        ]

        bars = ax.bar(metrics, scores, color=colors, alpha=0.8)
        ax.set_ylabel(ylabel)
        ax.set_title(title, fontweight="bold")
        ax.set_ylim(0, 100)

        # ì ìˆ˜ ë ˆì´ë¸” ì¶”ê°€
        for bar, score in zip(bars, scores):
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height,
                f"{score:.1f}",
                ha="center",
                va="bottom",
            )

    def _plot_log_distribution(self, ax, data):
        """ë¡œê·¸ ë ˆë²¨ ë¶„í¬ ì‹œê°í™”"""
        log_counts = data["log_counts"]

        if self.use_english_labels:
            no_data_text = "No log data"
            title = "Log Level Distribution"
        else:
            no_data_text = "ë¡œê·¸ ë°ì´í„° ì—†ìŒ"
            title = "ë¡œê·¸ ë ˆë²¨ ë¶„í¬"

        if not log_counts:
            ax.text(
                0.5,
                0.5,
                no_data_text,
                ha="center",
                va="center",
                transform=ax.transAxes,
            )
            ax.set_title(title, fontweight="bold")
            return

        levels = list(log_counts.keys())
        counts = list(log_counts.values())
        colors = {
            "INFO": "#2196F3",
            "SUCCESS": "#4CAF50",
            "WARNING": "#FF9800",
            "ERROR": "#F44336",
            "DEBUG": "#9E9E9E",
            "SYSTEM": "#9C27B0",
        }

        pie_colors = [colors.get(level, "#9E9E9E") for level in levels]

        wedges, texts, autotexts = ax.pie(
            counts, labels=levels, colors=pie_colors, autopct="%1.1f%%", startangle=90
        )
        ax.set_title(title, fontweight="bold")

        # í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ê°œì„ 
        for autotext in autotexts:
            autotext.set_color("white")
            autotext.set_fontweight("bold")

    def _save_individual_plots(self, data, output_dir, timestamp):
        """ê°œë³„ ì‹œê°í™” ì €ì¥"""
        try:
            # ê° ì‹œê°í™”ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥
            if self.use_english_labels:
                plot_configs = [
                    (
                        "workflow_progress",
                        self._plot_workflow_progress,
                        "workflow_progress",
                    ),
                    ("execution_times", self._plot_execution_times, "execution_times"),
                    ("reference_stats", self._plot_reference_stats, "reference_stats"),
                    (
                        "editorial_review",
                        self._plot_editorial_review,
                        "editorial_review",
                    ),
                    ("quality_metrics", self._plot_quality_metrics, "quality_metrics"),
                    (
                        "log_distribution",
                        self._plot_log_distribution,
                        "log_distribution",
                    ),
                ]
            else:
                plot_configs = [
                    (
                        "workflow_progress",
                        self._plot_workflow_progress,
                        "ì›Œí¬í”Œë¡œìš°_ì§„í–‰ìƒí™©",
                    ),
                    ("execution_times", self._plot_execution_times, "ì‘ì—…ë³„_ì†Œìš”ì‹œê°„"),
                    ("reference_stats", self._plot_reference_stats, "ì°¸ê³ ë¬¸í—Œ_í†µê³„"),
                    (
                        "editorial_review",
                        self._plot_editorial_review,
                        "í¸ì§‘ì¥_ê²€í† ê²°ê³¼",
                    ),
                    ("quality_metrics", self._plot_quality_metrics, "ë³´ê³ ì„œ_í’ˆì§ˆì§€í‘œ"),
                    ("log_distribution", self._plot_log_distribution, "ë¡œê·¸_ë ˆë²¨ë¶„í¬"),
                ]

            for plot_id, plot_func, title in plot_configs:
                fig, ax = plt.subplots(figsize=(10, 6))
                plot_func(ax, data)
                plt.tight_layout()

                filename = f"{title}_{timestamp}.png"
                filepath = os.path.join(output_dir, filename)
                plt.savefig(filepath, dpi=300, bbox_inches="tight")
                plt.close()

            if self.use_english_labels:
                print(f"ğŸ“ˆ Individual visualizations saved: {len(plot_configs)} files")
            else:
                print(f"ğŸ“ˆ ê°œë³„ ì‹œê°í™” {len(plot_configs)}ê°œ ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            error_msg = (
                f"Error saving individual plots: {e}"
                if self.use_english_labels
                else f"ê°œë³„ ì‹œê°í™” ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}"
            )
            print(f"âŒ {error_msg}")


# LangGraph ìƒíƒœ ì •ì˜
class ReportState(TypedDict):
    topic: str
    outline: str
    report_content: Dict[str, str]
    current_report_text: str
    review_result: dict
    review_history: List[dict]
    review_attempts: int
    formatted_report: str
    final_report_with_refs: str
    progress_message: str


# =============================================================================
# ëª¨ë¸ ë° Thinking Budget ì„¤ì • (generate_report.py ì°¸ì¡°)
# =============================================================================
# USE_PRODUCTION_MODELS = True # GUIì—ì„œ ì„ íƒí•˜ë„ë¡ ë³€ê²½

# í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ ë° ì˜ˆì‚°
TEST_MODELS = {
    "outline_generation": "gemini-2.5-flash-lite-preview-06-17",
    "draft_generation": "gemini-2.5-flash-lite-preview-06-17",
    "editorial_review": "gemini-2.5-flash-lite-preview-06-17",
    "final_formatting": "gemini-2.5-flash-lite-preview-06-17",
}
TEST_THINKING_BUDGETS = {
    "outline_generation": 0,
    "draft_generation": 0,
    "editorial_review": 8192,
    "final_formatting": 0,
}

# í”„ë¡œë•ì…˜ìš© ëª¨ë¸ ë° ì˜ˆì‚°
PRODUCTION_MODELS = {
    "outline_generation": "gemini-2.5-pro",
    "draft_generation": "gemini-2.5-pro",
    "editorial_review": "gemini-2.5-pro",  # ì¤‘ìš” ì‘ì—…ì€ Pro ìœ ì§€
    "final_formatting": "gemini-2.5-pro",
}
PRODUCTION_THINKING_BUDGETS = {
    "outline_generation": 128,
    "draft_generation": 128,
    "editorial_review": 8192,
    "final_formatting": 128,
}

# # í˜„ì¬ ì‚¬ìš©í•  ëª¨ë¸ ë° ì˜ˆì‚° ì„¤ì • -> ë™ì ìœ¼ë¡œ ë³€ê²½
# MODELS = PRODUCTION_MODELS if USE_PRODUCTION_MODELS else TEST_MODELS
# THINKING_BUDGETS = (
#     PRODUCTION_THINKING_BUDGETS if USE_PRODUCTION_MODELS else TEST_THINKING_BUDGETS
# )

DB_INDEX_PATH = "vector_db.faiss"
DB_DATA_PATH = "vector_db_data.json"
EMBEDDING_MODEL = "models/text-embedding-004"
MAX_REVIEW_ATTEMPTS = 3  # í¸ì§‘ì¥ ê²€í†  ìµœëŒ€ ì‹œë„ íšŸìˆ˜ (2 -> 3ìœ¼ë¡œ ì¦ê°€)
# =============================================================================

NUM_CLUSTERS_FOR_OUTLINE = 15
K_FOR_TOPIC_SEARCH = 15
K_FOR_SECTION_DRAFT = 25  # 10 -> 25ë¡œ ì¦ê°€ (ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰)


class RAGReportGeneratorAppV3:
    def __init__(self, root_window):
        self.root = root_window
        self.root.title("RAG ë¦¬í¬íŠ¸ ìƒì„±ê¸° v4 (ì§€ëŠ¥í˜•)")
        self.root.geometry("500x350")  # ì°½ í¬ê¸° í™•ëŒ€

        self.index = None
        self.db_data = None
        self.all_vectors = None
        self.client = None  # API í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        self.chunk_id_map = {}  # chunk_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë°ì´í„° ë§µ
        self.graph = None  # LangGraph ì¸ìŠ¤í„´ìŠ¤
        self.logger = ConsoleLogger()  # ì½˜ì†” ë¡œê±° ì¶”ê°€
        self.analyzer = ReportAnalyzer()  # ì‹œê°í™” ë¶„ì„ê¸° ì¶”ê°€

        # ì‹¤í–‰ ëª¨ë“œ ì„ íƒìš© ë³€ìˆ˜
        self.mode_var = tk.StringVar(value="Production")
        self.models = {}
        self.thinking_budgets = {}

        # ê°ì£¼/ì°¸ê³ ë¬¸í—Œ ì¶”ì ìš© -> í”Œë ˆì´ìŠ¤í™€ë” ë§¤í•‘ìš©ìœ¼ë¡œ ë³€ê²½
        self.ref_placeholder_map = {}
        self.progress_queue = queue.Queue()

        # ê²°ê³¼ í´ë” ê²½ë¡œë“¤ ì´ˆê¸°í™”
        self.results_folder = None
        self.logs_folder = None
        self.viz_folder = None

        self._configure_api()
        if self._load_vector_db():
            self._setup_gui()
            self._print_model_configuration()
            self.graph = self._build_graph()  # ì•± ì‹œì‘ ì‹œ ê·¸ë˜í”„ ë¹Œë“œ
            self.process_queue()  # í ì²˜ë¦¬ ì‹œì‘

    def _print_model_configuration(self):
        """í˜„ì¬ ëª¨ë¸ ì„¤ì •ì„ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤."""
        mode = self.mode_var.get()
        models_to_print = PRODUCTION_MODELS if mode == "Production" else TEST_MODELS
        budgets_to_print = (
            PRODUCTION_THINKING_BUDGETS if mode == "Production" else TEST_THINKING_BUDGETS
        )

        print(f"\n=== ëª¨ë¸ ì„¤ì • ({mode} ëª¨ë“œ) ===")
        for task, model in models_to_print.items():
            budget = budgets_to_print.get(task)
            budget_str = f" (Thinking Budget: {budget})" if budget is not None else ""
            print(f"  - {task}: {model}{budget_str}")
        print("=" * 40)

    def _setup_gui(self):
        self.label = tk.Label(
            self.root, text="ìƒì„±í•  ë³´ê³ ì„œì˜ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", wraplength=380
        )
        self.label.pack(pady=10)
        self.topic_entry = tk.Entry(self.root, width=50)
        self.topic_entry.pack(pady=5, padx=10, fill=tk.X)

        # ì‹¤í–‰ ëª¨ë“œ ì„ íƒ GUI
        mode_frame = tk.Frame(self.root)
        mode_frame.pack(pady=5)
        tk.Label(mode_frame, text="ì‹¤í–‰ ëª¨ë“œ:").pack(side=tk.LEFT, padx=5)
        prod_radio = tk.Radiobutton(
            mode_frame,
            text="Production",
            variable=self.mode_var,
            value="Production",
            command=self._print_model_configuration,
        )
        prod_radio.pack(side=tk.LEFT)
        test_radio = tk.Radiobutton(
            mode_frame,
            text="Test",
            variable=self.mode_var,
            value="Test",
            command=self._print_model_configuration,
        )
        test_radio.pack(side=tk.LEFT)

        self.generate_button = tk.Button(
            self.root, text="ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", command=self.run_generation_pipeline
        )
        self.generate_button.pack(pady=10)

        # ì‹œê°í™” ë²„íŠ¼ ì¶”ê°€
        self.visualization_button = tk.Button(
            self.root,
            text="ìµœê·¼ ì‹œê°í™” ë³´ê¸°",
            command=self.show_latest_visualization,
            state="disabled",
        )
        self.visualization_button.pack(pady=5)

        # ë¡œê·¸ íŒŒì¼ ë³´ê¸° ë²„íŠ¼ ì¶”ê°€
        self.log_button = tk.Button(
            self.root,
            text="ë¡œê·¸ íŒŒì¼ ë³´ê¸°",
            command=self.show_log_files,
            state="disabled",
        )
        self.log_button.pack(pady=5)

        # ìƒíƒœ í‘œì‹œ ë¼ë²¨
        self.status_label = tk.Label(self.root, text="ì¤€ë¹„ë¨", fg="green")
        self.status_label.pack(pady=5)

        # ìµœê·¼ ìƒì„±ëœ íŒŒì¼ ê²½ë¡œë“¤ì„ ì €ì¥í•  ë³€ìˆ˜
        self.latest_dashboard_path = None
        self.latest_log_path = None

    def _configure_api(self):
        load_dotenv()
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            messagebox.showerror(
                "ì˜¤ë¥˜", "GEMINI_API_KEYë¥¼ .env íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
            self.root.destroy()
            sys.exit(1)
        google.generativeai.configure(api_key=api_key)
        self.client = genai.Client(api_key=api_key)
        # self.embedding_model_instance = genai.GenerativeModel(
        #     EMBEDDING_MODEL, client=self.client
        # )  # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    def _load_vector_db(self):
        try:
            if not os.path.exists(DB_INDEX_PATH) or not os.path.exists(DB_DATA_PATH):
                messagebox.showerror(
                    "ì˜¤ë¥˜",
                    f"'{DB_INDEX_PATH}' ë˜ëŠ” '{DB_DATA_PATH}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                )
                self.root.destroy()
                return False
            self.index = faiss.read_index(DB_INDEX_PATH)
            with open(DB_DATA_PATH, "r", encoding="utf-8") as f:
                self.db_data = json.load(f)

            # DBì˜ ëª¨ë“  ë²¡í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ
            self.all_vectors = np.array(
                [self.index.reconstruct(i) for i in range(self.index.ntotal)]
            ).astype("float32")

            # chunk_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë§µì„ ìƒì„± (reference_textê°€ ìˆëŠ” ê²ƒë§Œ)
            self.chunk_id_map = {
                item["chunk_id"]: item
                for item in self.db_data
                if "chunk_id" in item and item.get("reference_text")
            }

            # í†µê³„ ì¶œë ¥
            total_chunks = len(self.db_data)
            with_references = len(self.chunk_id_map)

            print(f"\n=== Vector DB ë¡œë“œ ì™„ë£Œ ===")
            print(f"  - ì „ì²´ ì²­í¬: {total_chunks}")
            print(f"  - ì°¸ê³ ë¬¸í—Œ ìˆëŠ” ì²­í¬: {with_references}")
            print(f"  - ì°¸ê³ ë¬¸í—Œ ë¹„ìœ¨: {with_references/total_chunks*100:.1f}%")
            print("=" * 40)

            messagebox.showinfo(
                "DB ë¡œë“œ ì™„ë£Œ",
                f"ì´ {self.index.ntotal}ê°œì˜ ë²¡í„°ê°€ í¬í•¨ëœ DBë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\nì°¸ê³ ë¬¸í—Œ ìˆëŠ” ì²­í¬: {with_references}ê°œ ({with_references/total_chunks*100:.1f}%)",
            )
            return True
        except Exception as e:
            messagebox.showerror("DB ë¡œë“œ ì‹¤íŒ¨", f"DB íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.root.destroy()
            return False

    def _search_similar_documents(self, query, k=10):
        query_embedding = google.generativeai.embed_content(
            model=EMBEDDING_MODEL,
            content=query,
            task_type="RETRIEVAL_QUERY",
        )["embedding"]

        # ë” ë§ì€ í›„ë³´ë¥¼ ê²€ìƒ‰í•´ì„œ ì°¸ê³ ë¬¸í—Œ ìˆëŠ” ê²ƒì„ ìš°ì„  ì„ íƒ
        candidate_k = min(k * 3, len(self.db_data))  # 3ë°° ë” ê²€ìƒ‰
        distances, indices = self.index.search(
            np.array([query_embedding], dtype="float32"), candidate_k
        )

        candidates = [self.db_data[i] for i in indices[0]]

        # ì°¸ê³ ë¬¸í—Œ ìˆëŠ” ê²ƒì„ ìš°ì„  ì„ íƒ
        with_refs = [c for c in candidates if c.get("reference_text")]
        without_refs = [c for c in candidates if not c.get("reference_text")]

        # ì°¸ê³ ë¬¸í—Œ ìˆëŠ” ê²ƒì„ ìš°ì„ í•˜ë˜, ì´ kê°œê°€ ë˜ë„ë¡ ì¡°ì •
        result = with_refs[:k] + without_refs[: max(0, k - len(with_refs))]

        return result[:k]

    def _get_model_for_task(self, task_name):
        model_name = self.models.get(task_name, "gemini-1.5-flash-latest")
        # print(f"[{task_name}] ëª¨ë¸: {model_name}") # ê°œë³„ ë¡œê¹…ì€ _print_model_configurationìœ¼ë¡œ ëŒ€ì²´
        return model_name

    def _get_generation_config(self, task_name):
        """ì‘ì—…ì— ë§ëŠ” GenerateContentConfigë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (thinking_budget í¬í•¨)."""
        budget = self.thinking_budgets.get(task_name)

        # budget=0ë„ ìœ íš¨í•œ ê°’ì´ë¯€ë¡œ is not Noneìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
        if budget is not None:
            # ê³µì‹ ë¬¸ì„œì— ë”°ë¼ types.GenerateContentConfigì™€ types.ThinkingConfigë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            return types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(thinking_budget=budget)
            )

        # ì˜ˆì‚°ì´ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°, ê¸°ë³¸ê°’ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        return None

    def _extract_key_themes(self):
        """K-Means í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ DBì˜ í•µì‹¬ ì£¼ì œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if self.index.ntotal < NUM_CLUSTERS_FOR_OUTLINE:
            num_clusters = self.index.ntotal
        else:
            num_clusters = NUM_CLUSTERS_FOR_OUTLINE

        kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
        kmeans.fit(self.all_vectors)

        representative_indices = []
        for i in range(num_clusters):
            cluster_indices = np.where(kmeans.labels_ == i)[0]
            if len(cluster_indices) > 0:
                # ê° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ì— ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œ(ë²¡í„°) ì°¾ê¸°
                cluster_center = kmeans.cluster_centers_[i]
                distances = faiss.pairwise_distances(
                    cluster_center.reshape(1, -1), self.all_vectors[cluster_indices]
                )
                closest_in_cluster = np.argmin(distances)
                representative_indices.append(cluster_indices[closest_in_cluster])

        return [self.db_data[i] for i in representative_indices]

    def _generate_outline_logic(self, topic):
        """ê°œìš” ìƒì„± ë¡œì§ (ê¸°ì¡´ _generate_outline)"""
        # 1. Vector DB ì „ì²´ì—ì„œ í•µì‹¬ ì£¼ì œ ì¶”ì¶œ (Broad View)
        key_theme_contexts = self._extract_key_themes()

        # 2. ì‚¬ìš©ì ì£¼ì œì™€ ì§ì ‘ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰ (Focused View)
        topic_specific_contexts = self._search_similar_documents(
            topic, k=K_FOR_TOPIC_SEARCH
        )

        # 3. ë‘ ì»¨í…ìŠ¤íŠ¸ë¥¼ í•©ì¹˜ê³  ì¤‘ë³µ ì œê±°
        combined_contexts = {
            item["sentence"]: item
            for item in key_theme_contexts + topic_specific_contexts
        }.values()

        context_str = "\n\n---\n\n".join(
            [
                f"ë¬¸ì„œ: {c['file_path']}\nëª©ì°¨: {' > '.join(c['headers'])}\në¬¸ì¥: {c['sentence']}"
                for c in combined_contexts
            ]
        )

        prompt = f"""
        ë‹¹ì‹ ì€ ë²•ë¥  ì •ì±… ì—°êµ¬ì†Œì˜ ìˆ˜ì„ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ë°©ëŒ€í•œ ì–‘ì˜ ë¦¬ì„œì¹˜ ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë³´ê³ ì„œì˜ ê°œìš”ë¥¼ ì„¤ê³„í•˜ëŠ” ì„ë¬´ë¥¼ ë§¡ì•˜ìŠµë‹ˆë‹¤.

        **ë¶„ì„ëœ ìë£Œ:**
        - **í•µì‹¬ ì£¼ì œ ê·¸ë£¹:** ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ì¶œí•œ í•µì‹¬ ì£¼ì œë“¤ì…ë‹ˆë‹¤. ë°ì´í„°ì˜ ì „ì²´ì ì¸ ê·¸ë¦¼ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
        - **ìš”ì²­ ì£¼ì œ ê´€ë ¨ ìë£Œ:** ì‚¬ìš©ìê°€ ìš”ì²­í•œ íŠ¹ì • ì£¼ì œì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ìë£Œë“¤ì…ë‹ˆë‹¤.

        **í•µì‹¬ ë³´ê³ ì„œ ì£¼ì œ:** "{topic}"

        **ì§€ì‹œì‚¬í•­:**
        1.  **ì¢…í•©ì  ë¶„ì„:** 'í•µì‹¬ ì£¼ì œ ê·¸ë£¹'ê³¼ 'ìš”ì²­ ì£¼ì œ ê´€ë ¨ ìë£Œ'ë¥¼ ëª¨ë‘ í™œìš©í•˜ì—¬, ë‘ ê´€ì ì„ í†µí•©í•˜ëŠ” ì¢…í•©ì ì¸ ë³´ê³ ì„œ ëª©ì°¨ë¥¼ ë§Œë“œì„¸ìš”. ì–´ëŠ í•œìª½ì˜ ì •ë³´ë„ ëˆ„ë½í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
        2.  **ë…¼ë¦¬ì  êµ¬ì¡° ì„¤ê³„:** ì„œë¡ -ë³¸ë¡ -ê²°ë¡ ì˜ ëª…í™•í•œ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”. ë³¸ë¡ ì€ ì—¬ëŸ¬ ê°œì˜ ì¥(Chapter)ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ì¥ì€ ë‹¤ì‹œ ì—¬ëŸ¬ ì ˆ(Section)ìœ¼ë¡œ ì„¸ë¶„í™”í•˜ì—¬ ë§¤ìš° ìƒì„¸í•˜ê³  ì²´ê³„ì ì¸ êµ¬ì¡°ë¥¼ ê°–ì¶°ì•¼ í•©ë‹ˆë‹¤.
        3.  **ìµœì¢… ëª©í‘œ ì§€í–¥:** ë³´ê³ ì„œì˜ ìµœì¢… ëª©í‘œëŠ” 'í•œêµ­ì˜ ì‚¬ë‚´ ë³€í˜¸ì‚¬ ACP ë„ì…ì„ ìœ„í•œ ë²•ì , ì •ì±…ì  ì‹œì‚¬ì  ë„ì¶œ'ì…ë‹ˆë‹¤. ëª¨ë“  ëª©ì°¨ êµ¬ì„±ì€ ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ëŠ” ê³¼ì •ì´ ë˜ë„ë¡ ì„¤ê³„í•˜ì„¸ìš”. ìœ ëŸ½ ì‚¬ë¡€ ë¶„ì„, ì´ë¡ ì  ë°°ê²½, ê°êµ­ ë¹„êµ ë“±ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ë°°ì¹˜í•˜ì—¬ ìµœì¢… ê²°ë¡ ìœ¼ë¡œ ì—°ê²°ë˜ê²Œ í•˜ì„¸ìš”.
        4.  **ì¶œë ¥ í˜•ì‹:** ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, ì˜¤ì§ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ëª©ì°¨ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

        --- ë¶„ì„ëœ ì°¸ê³  ìë£Œ (í•µì‹¬ ì£¼ì œ ë° ìš”ì²­ ì£¼ì œ ê´€ë ¨) ---
        {context_str}
        --- ë ---

        ìœ„ ì§€ì‹œì‚¬í•­ê³¼ ëª©í‘œì— ë”°ë¼, ë°ì´í„°ë² ì´ìŠ¤ì˜ ì „ì²´ì ì¸ ë‚´ìš©ê³¼ ì‚¬ìš©ìì˜ íŠ¹ì • ìš”êµ¬ë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ëŠ”, ë§¤ìš° ì™„ì„±ë„ ë†’ì€ ë³´ê³ ì„œ ëª©ì°¨ë¥¼ ì‘ì„±í•´ì£¼ì‹­ì‹œì˜¤.
        """
        model_name = self._get_model_for_task("outline_generation")
        config = self._get_generation_config("outline_generation")
        response = self.client.models.generate_content(
            model=model_name, contents=prompt, config=config
        )
        return response.text

    def _generate_single_section(self, header, topic, improvement_instructions=""):
        """í•˜ë‚˜ì˜ ì„¹ì…˜ ë³¸ë¬¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ê°œì„  ì§€ì¹¨ ì¶”ê°€)"""
        # ë‹¤ì–‘í•œ ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ë” ë§ì€ ì°¸ê³ ë¬¸í—Œ ì°¾ê¸°
        queries = [
            f"{topic} - {header}",
            f"{header}",
            f"{topic} {header}",
            f"{header} ì‚¬ë¡€ íŒë¡€",
            f"{header} ë²•ë¥  ì œë„",
        ]

        all_contexts = []
        seen_sentences = set()

        for query in queries:
            contexts = self._search_similar_documents(
                query, k=K_FOR_SECTION_DRAFT // len(queries) + 2
            )
            for c in contexts:
                if c["sentence"] not in seen_sentences:
                    all_contexts.append(c)
                    seen_sentences.add(c["sentence"])

        # ìƒìœ„ K_FOR_SECTION_DRAFTê°œë§Œ ì„ íƒ
        contexts = all_contexts[:K_FOR_SECTION_DRAFT]

        context_str = ""
        valid_citations = []  # ìœ íš¨í•œ ì¸ìš©ë§Œ ì €ì¥
        context_without_refs = []  # ì°¸ê³ ë¬¸í—Œ ì—†ëŠ” ì»¨í…ìŠ¤íŠ¸

        for i, c in enumerate(contexts):
            context_str += f"--- ì»¨í…ìŠ¤íŠ¸ {i+1} ---\n"
            context_str += f"ì°¸ê³  ë¬¸ì¥: {c['sentence']}\n"

            # reference_textì™€ chunk_idê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°ì—ë§Œ CITATION íƒœê·¸ ì œê³µ
            if c.get("reference_text") and c.get("chunk_id"):
                citation_tag = f"[CITATION:{c['chunk_id']}]"
                context_str += f"ğŸ”– í•„ìˆ˜ ì°¸ê³ ë¬¸í—Œ íƒœê·¸: {citation_tag}\n"
                valid_citations.append(c["chunk_id"])
            else:
                context_str += f"âš ï¸ ì°¸ê³ ë¬¸í—Œ íƒœê·¸ ì—†ìŒ (ë‚´ìš©ë§Œ ì°¸ê³ )\n"
                context_without_refs.append(c)

        # ì°¸ê³ ë¬¸í—Œ ë¹„ìœ¨ ê³„ì‚°
        ref_ratio = len(valid_citations) / len(contexts) * 100 if contexts else 0
        print(
            f"  - ì„¹ì…˜ '{header}': ì´ {len(contexts)}ê°œ ì»¨í…ìŠ¤íŠ¸ ì¤‘ {len(valid_citations)}ê°œ ì°¸ê³ ë¬¸í—Œ ({ref_ratio:.1f}%)"
        )

        # ìœ íš¨í•œ citation ê°•ì¡°
        if valid_citations:
            citation_list = "\n".join(
                [
                    f"  ğŸ”– {i+1}. [CITATION:{cid}]"
                    for i, cid in enumerate(valid_citations)
                ]
            )
            citation_instruction = f"""
ğŸš¨ **ë°˜ë“œì‹œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì°¸ê³ ë¬¸í—Œ íƒœê·¸ ëª©ë¡** ğŸš¨
{citation_list}

âš ï¸ **í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­:**
- ìœ„ íƒœê·¸ë“¤ì„ ìµœëŒ€í•œ ë§ì´ ì‚¬ìš©í•˜ì„¸ìš” (ëª©í‘œ: 80% ì´ìƒ)
- íƒœê·¸ëŠ” ì •í™•íˆ ë³µì‚¬í•˜ì—¬ ë¬¸ì¥ ëì— ë¶™ì´ì„¸ìš”
- ì ˆëŒ€ ì„ì˜ë¡œ [^1] ê°™ì€ ê°ì£¼ ë²ˆí˜¸ë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
"""
        else:
            citation_instruction = """
âš ï¸ **ì£¼ì˜:** ì´ ì„¹ì…˜ì—ëŠ” ì°¸ê³ ë¬¸í—Œ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.
- ëª¨ë“  ë‚´ìš©ì€ ì°¸ê³ í•˜ë˜ ì¸ìš© íƒœê·¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì ˆëŒ€ ì„ì˜ë¡œ [^1] ê°™ì€ ê°ì£¼ ë²ˆí˜¸ë¥¼ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
"""

        # ê°œì„  ì§€ì¹¨ì´ ìˆë‹¤ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        improvement_prompt_part = ""
        if improvement_instructions:
            improvement_prompt_part = f"""
ğŸ”§ **í¸ì§‘ì¥ ê°œì„  ì§€ì‹œì‚¬í•­:**
{improvement_instructions}
"""

        prompt = f"""
ğŸ¯ **ì„ë¬´:** ë²•ë¥  ë³´ê³ ì„œ '{header}' ì„¹ì…˜ì˜ ì „ë¬¸ì ì¸ ë³¸ë¬¸ ì‘ì„±

**ë³´ê³ ì„œ ì£¼ì œ:** {topic}
**í˜„ì¬ ì„¹ì…˜:** {header}
{improvement_prompt_part}

{citation_instruction}

ğŸ¯ **í•µì‹¬ ì§€ì‹œì‚¬í•­:**
1. **ì°¸ê³ ë¬¸í—Œ íƒœê·¸ ìš°ì„  ì‚¬ìš©**: ğŸ”– í‘œì‹œëœ íƒœê·¸ë¥¼ ìµœëŒ€í•œ ë§ì´ ì‚¬ìš©í•˜ì„¸ìš”
2. **ì •í™•í•œ ë³µì‚¬**: íƒœê·¸ëŠ” ì •í™•íˆ ë³µì‚¬í•˜ì—¬ ê´€ë ¨ ë¬¸ì¥ ëì— ë¶™ì´ì„¸ìš”
3. **ì„ì˜ ìƒì„± ê¸ˆì§€**: [^1], [1] ê°™ì€ ê°ì£¼ ë²ˆí˜¸ëŠ” ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
4. **ì°¸ê³ ìë£Œ ê¸°ë°˜**: ì£¼ì–´ì§„ ì°¸ê³  ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš” (ì™¸ë¶€ ì§€ì‹ ê¸ˆì§€)
5. **ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°**: ë¬¸ë‹¨ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°í•˜ê³  ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì„¸ìš”

--- ğŸ“š ì°¸ê³ ìë£Œ ---
{context_str}
--- ë ---

ìœ„ ì§€ì‹œì‚¬í•­ì„ ì¤€ìˆ˜í•˜ì—¬ ì „ë¬¸ì ì¸ ë³¸ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.
"""
        model_name = self._get_model_for_task("draft_generation")
        config = self._get_generation_config("draft_generation")
        response = self.client.models.generate_content(
            model=model_name, contents=prompt, config=config
        )

        # AI ì‘ë‹µì—ì„œ ì‹¤ì œë¡œ íƒœê·¸ë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€ ê²€ì¦
        response_text = response.text
        
        # ìƒˆë¡œìš´ ê²€ì¦ ë¡œì§
        returned_citation_ids = set(re.findall(r"\[CITATION:(.*?)\]", response_text))
        provided_citation_ids = set(valid_citations)

        correctly_used_ids = provided_citation_ids.intersection(returned_citation_ids)
        hallucinated_ids = returned_citation_ids.difference(provided_citation_ids)
        
        num_correctly_used = len(correctly_used_ids)
        num_expected = len(provided_citation_ids)
        num_hallucinated = len(hallucinated_ids)

        # ë¡œê·¸ ë©”ì‹œì§€ ìƒì„±
        if num_expected > 0:
            usage_percent = (num_correctly_used / num_expected) * 100
            log_msg = f"    ğŸ“Š íƒœê·¸ ì‚¬ìš© ê²€ì¦: {num_correctly_used}/{num_expected}ê°œ ì‚¬ìš© ({usage_percent:.1f}%)"
        else:
            log_msg = "    ğŸ“Š íƒœê·¸ ì‚¬ìš© ê²€ì¦: ì°¸ê³ ë¬¸í—Œ ì—†ìŒ"
        
        if num_hallucinated > 0:
            log_msg += f" | âš ï¸ ìƒì„±ëœ(hallucinated) íƒœê·¸: {num_hallucinated}ê°œ"
        
        print(log_msg)


        # íƒœê·¸ ì‚¬ìš©ë¥ ì´ ë‚®ìœ¼ë©´ ê²½ê³ 
        if num_expected > 0 and (num_correctly_used / num_expected) < 0.5:
            print(
                f"    âš ï¸ ê²½ê³ : AIê°€ ì œê³µëœ {num_expected}ê°œ íƒœê·¸ ì¤‘ {num_correctly_used}ê°œë§Œ ì˜¬ë°”ë¥´ê²Œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
            )

        return response_text

    def _editorial_review_logic(self, report_text, outline):
        """í¸ì§‘ì¥ ê²€í†  ë¡œì§ (ê¸°ì¡´ _editorial_review)"""
        prompt = f"""
        ë‹¹ì‹ ì€ ë²•ë¥  ë³´ê³ ì„œ ì „ë¬¸ í¸ì§‘ì¥ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ë³´ê³ ì„œ ê°œìš”'ì™€ 'ì‘ì„±ëœ ì´ˆì•ˆ'ì„ ë¹„êµí•˜ì—¬, ì´ˆì•ˆì˜ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ê°œì„  ì§€ì¹¨ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

        **ê²€í†  ì§€ì‹œì‚¬í•­:**
        1. 'ì‘ì„±ëœ ì´ˆì•ˆ'ì´ 'ë³´ê³ ì„œ ê°œìš”'ì˜ ëª¨ë“  í•­ëª©ì„ ì¶©ì‹¤í•˜ê²Œ ë‹¤ë£¨ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        2. ê° ì„¹ì…˜ë³„ë¡œ ë‚´ìš©ì´ ë¶€ì‹¤í•˜ê±°ë‚˜, ë…¼ë¦¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, ë¶„ì„ì˜ ê¹Šì´ê°€ ì–•ì€ ë¶€ë¶„ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
        3. ëª¨ë“  ë‚´ìš©ì´ ì™„ë²½í•˜ë‹¤ë©´ "sections_to_improve"ë¥¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ `[]`ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        4. ê°œì„ ì´ í•„ìš”í•˜ë‹¤ë©´, **ì–´ë–¤ ì„¹ì…˜ì„(section_header), ì™œ(reason), ì–´ë–»ê²Œ(how_to_improve)** ê°œì„ í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì ì¸ ì§€ì¹¨ì„ ì‘ì„±í•©ë‹ˆë‹¤. 'how_to_improve'ëŠ” ì‹¤ì œ ì¬ì‘ì„± AIì—ê²Œ ì „ë‹¬ë  ëª…í™•í•œ ì§€ì‹œì—¬ì•¼ í•©ë‹ˆë‹¤.
        5. ë‹¹ì‹ ì˜ ì˜ê²¬ì´ë‚˜ ë¶„ì„ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ê³ , ì˜¤ì§ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

        --- ë³´ê³ ì„œ ê°œìš” ---
        {outline}
        --- ë ---

        --- ì‘ì„±ëœ ì´ˆì•ˆ ---
        {report_text}
        --- ë ---

        **ì¶œë ¥ í˜•ì‹ (ì˜¤ì§ JSONë§Œ):**
        ```json
        {{
          "review_passed": boolean,
          "sections_to_improve": [
            {{
              "section_header": "### ìˆ˜ì •ì´ í•„ìš”í•œ ì„¹ì…˜ ì „ì²´ ì œëª© 1",
              "reason": "í˜„ì¬ ë‚´ìš©ì´ ë„ˆë¬´ ì¶”ìƒì ì´ê³  êµ¬ì²´ì ì¸ ì‚¬ë¡€ê°€ ë¶€ì¡±í•¨.",
              "how_to_improve": "ì œê³µëœ ì°¸ê³ ìë£Œì—ì„œ ë…ì¼ì˜ íŒë¡€ 2ê°€ì§€ì™€ í”„ë‘ìŠ¤ì˜ ê´€ë ¨ ë²• ì¡°í•­ 1ê°€ì§€ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¸ìš©í•˜ì—¬, ì£¼ì¥ì„ ë’·ë°›ì¹¨í•˜ëŠ” êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ 2~3ë¬¸ë‹¨ì— ê±¸ì³ ìƒì„¸íˆ ë³´ê°•í•  ê²ƒ."
            }}
          ]
        }}
        ```
        """
        model_name = self._get_model_for_task("editorial_review")
        config = self._get_generation_config("editorial_review")
        response = self.client.models.generate_content(
            model=model_name, contents=prompt, config=config
        )

        try:
            json_text = re.search(
                r"```json\n(.*)\n```", response.text, re.DOTALL
            ).group(1)
            return json.loads(json_text)
        except Exception as e:
            print(f"í¸ì§‘ì¥ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\nì‘ë‹µ ë‚´ìš©: {response.text}")
            # ë¬´ì¡°ê±´ í†µê³¼ ëŒ€ì‹ , ì‹¤íŒ¨ë¡œ ì²˜ë¦¬í•˜ê³  ì¬ì‹œë„ë¥¼ ìœ ë„
            return {
                "review_passed": False,
                "sections_to_improve": [
                    {
                        "section_header": "ì „ì²´ ë³´ê³ ì„œ",
                        "reason": "í¸ì§‘ì¥ ê²€í†  ëª¨ë¸ì˜ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ë¡œ ìë™ ì¬ì‘ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                        "how_to_improve": "ë³´ê³ ì„œ ê°œìš”ì— ë§ì¶° ì „ì²´ì ì¸ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ë‹¤ì‹œ ê²€í† í•˜ê³ , ë…¼ë¦¬ì  íë¦„ì„ ë³´ê°•í•˜ì—¬ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.",
                    }
                ],
            }

    def _final_formatting_logic(self, report_text):
        """ìµœì¢… ì„œì‹ ì •ë¦¬ ë¡œì§ (ê¸°ì¡´ _final_formatting)"""
        prompt = f"""
        ë‹¹ì‹ ì€ ì¶œíŒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë³´ê³ ì„œ ì´ˆì•ˆì˜ ë‚´ìš©ì„ ë³€ê²½í•˜ì§€ ì•Šê³ , ì˜¤ì§ ë§ˆí¬ë‹¤ìš´ ì„œì‹ë§Œì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ì„ë¬´ë¥¼ ë§¡ì•˜ìŠµë‹ˆë‹¤.

        **ì§€ì‹œì‚¬í•­:**
        1. **ë‚´ìš© ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€:** ë‹¨ì–´ í•˜ë‚˜, ë¬¸ì¥ í•˜ë‚˜ë„ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€/ì‚­ì œí•˜ì§€ ë§ˆì„¸ìš”.
        2. **ì„œì‹ ìµœì í™”:** í—¤ë”(#, ##, ###)ì˜ ê³„ì¸µ êµ¬ì¡°ë¥¼ ëª…í™•íˆ í•˜ê³ , ëª©ë¡, ì¸ìš©êµ¬(>), ê°•ì¡°(**) ë“±ì„ ì¼ê´€ì„± ìˆê²Œ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
        3. **CITATION íƒœê·¸ ì ˆëŒ€ ìœ ì§€:** `[CITATION:...]` í˜•ì‹ì˜ íƒœê·¸ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ê±°ë‚˜ ì œê±°í•˜ì§€ ë§ˆì„¸ìš”. ì´ íƒœê·¸ëŠ” ê°ì£¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.
        4. **ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°:** ë³¸ë¬¸ì— ë‚¨ì•„ìˆëŠ” `ğŸ”–` ê¸°í˜¸ëŠ” ëª¨ë‘ ì œê±°í•´ì£¼ì„¸ìš”.
        5. **ì¶œë ¥:** ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, ì˜¤ì§ ì„œì‹ì´ ê°œì„ ëœ ìµœì¢… ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

        --- ì›ë³¸ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ---
        {report_text}
        --- ë ---

        ìœ„ ì§€ì‹œì‚¬í•­ì„ ì¤€ìˆ˜í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        """
        model_name = self._get_model_for_task("final_formatting")
        config = self._get_generation_config("final_formatting")
        response = self.client.models.generate_content(
            model=model_name, contents=prompt, config=config
        )
        return response.text

    def _finalize_citations_logic(self, final_text):
        """ê°ì£¼ ì²˜ë¦¬ ë¡œì§ (ê¸°ì¡´ _finalize_citations)"""
        # 1. ë³¸ë¬¸ì— ì‚¬ìš©ëœ CITATION IDë¥¼ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
        citation_ids_in_order = list(
            dict.fromkeys(re.findall(r"\[CITATION:(.*?)\]", final_text))
        )

        print(f"\n=== ì°¸ê³ ë¬¸í—Œ ì²˜ë¦¬ ìƒì„¸ ë¶„ì„ ===")
        print(f"ì „ì²´ ë°ì´í„° ì²­í¬: {len(self.db_data)}ê°œ")
        print(
            f"ì°¸ê³ ë¬¸í—Œ ìˆëŠ” ì²­í¬: {len(self.chunk_id_map)}ê°œ ({len(self.chunk_id_map)/len(self.db_data)*100:.1f}%)"
        )
        print(f"ë³¸ë¬¸ì—ì„œ ë°œê²¬ëœ CITATION íƒœê·¸: {len(citation_ids_in_order)}ê°œ")

        if not citation_ids_in_order:
            print("âŒ ë³¸ë¬¸ì—ì„œ CITATION íƒœê·¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print("ğŸ” AIê°€ ì°¸ê³ ë¬¸í—Œ íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")
            return final_text, ""

        # 2. ìœ íš¨í•œ chunk_idë§Œ í•„í„°ë§
        valid_citation_ids = []
        invalid_citation_ids = []

        for chunk_id in citation_ids_in_order:
            if chunk_id in self.chunk_id_map:
                # chunk_id_mapì—ëŠ” ì´ë¯¸ reference_textê°€ ìˆëŠ” ê²ƒë§Œ í¬í•¨ë˜ì–´ ìˆìŒ
                valid_citation_ids.append(chunk_id)
                print(f"    âœ… ìœ íš¨í•œ chunk_id: {chunk_id[:20]}...")
            else:
                invalid_citation_ids.append(chunk_id)
                print(f"    âŒ ë¬´íš¨í•œ chunk_id: '{chunk_id}'")

        if invalid_citation_ids:
            print(f"âš ï¸ ë¬´íš¨í•œ íƒœê·¸ {len(invalid_citation_ids)}ê°œë¥¼ ì œê±°í•©ë‹ˆë‹¤.")

        if not valid_citation_ids:
            print("âŒ ìœ íš¨í•œ ì°¸ê³ ë¬¸í—Œ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ” AIê°€ ì œê³µëœ íƒœê·¸ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            # ë¬´íš¨í•œ íƒœê·¸ë“¤ë§Œ ì œê±°í•˜ê³  ë°˜í™˜
            processed_text = final_text
            for invalid_id in invalid_citation_ids:
                processed_text = processed_text.replace(f"[CITATION:{invalid_id}]", "")
            return processed_text, ""

        # 3. ë¬´íš¨í•œ íƒœê·¸ë“¤ì„ ë³¸ë¬¸ì—ì„œ ì œê±°
        processed_text = final_text
        for invalid_id in invalid_citation_ids:
            processed_text = processed_text.replace(f"[CITATION:{invalid_id}]", "")

        # 4. ìœ íš¨í•œ íƒœê·¸ë§Œ ì²˜ë¦¬ - CITATION IDì™€ ì‹¤ì œ ê°ì£¼ ë²ˆí˜¸ ë§¤í•‘
        ref_number_map = {
            chunk_id: i + 1 for i, chunk_id in enumerate(valid_citation_ids)
        }

        # 5. ë³¸ë¬¸ì˜ íƒœê·¸ë¥¼ ê°ì£¼ ë²ˆí˜¸ë¡œ êµì²´
        for chunk_id, number in ref_number_map.items():
            processed_text = processed_text.replace(
                f"[CITATION:{chunk_id}]", f"[^{number}]"
            )

        # ë¶ˆí•„ìš”í•œ ğŸ”– ë§ˆì»¤ë¥¼ ìµœì¢…ì ìœ¼ë¡œ ì œê±°
        processed_text = processed_text.replace("ğŸ”–", "")

        # 6. ì°¸ê³ ë¬¸í—Œ ëª©ë¡ ìƒì„± (ìœ íš¨í•œ ê²ƒë§Œ)
        references_list_str = "\n\n---\n\n## ì°¸ê³ ë¬¸í—Œ\n\n"
        for i, chunk_id in enumerate(valid_citation_ids):
            number = i + 1
            original_ref_item = self.chunk_id_map[chunk_id]
            ref_text = original_ref_item["reference_text"]
            references_list_str += f"[^{number}]: {ref_text}\n"

        # ì„±ê³¼ ìš”ì•½
        usage_rate = len(valid_citation_ids) / len(self.chunk_id_map) * 100
        print(f"\nğŸ¯ ì°¸ê³ ë¬¸í—Œ í™œìš© ì„±ê³¼:")
        print(f"   - ì „ì²´ ì´ìš© ê°€ëŠ¥í•œ ì°¸ê³ ë¬¸í—Œ: {len(self.chunk_id_map)}ê°œ")
        print(f"   - ì‹¤ì œ ì‚¬ìš©ëœ ì°¸ê³ ë¬¸í—Œ: {len(valid_citation_ids)}ê°œ")
        print(f"   - í™œìš©ë¥ : {usage_rate:.1f}%")
        print(f"   - ìµœì¢… ì°¸ê³ ë¬¸í—Œ ëª©ë¡: {len(valid_citation_ids)}ê°œ")
        print("=" * 50)

        return processed_text, references_list_str

    # =============================================================================
    # LangGraph ë…¸ë“œ ì •ì˜
    # =============================================================================
    def node_generate_outline(self, state: ReportState):
        """ê°œìš” ìƒì„± ë…¸ë“œ"""
        self.logger.set_current_node("generate_outline")
        self.logger.add_log("INFO", "[1/6] ë³´ê³ ì„œ ê°œìš” ìƒì„± ì‹œì‘")

        topic = state["topic"]
        self.logger.add_log("INFO", f"ì£¼ì œ: {topic}")

        outline = self._generate_outline_logic(topic)
        self.logger.add_log("SUCCESS", f"ê°œìš” ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(outline)}ì)")

        return {
            "outline": outline,
            "progress_message": "1/6: ê°œìš” ìƒì„± ì™„ë£Œ. ì´ˆì•ˆ ì‘ì„± ì‹œì‘...",
        }

    def node_generate_draft(self, state: ReportState):
        """ì´ˆì•ˆ ìƒì„± ë…¸ë“œ"""
        self.logger.set_current_node("generate_draft")
        self.logger.add_log("INFO", "[2/6] ë³´ê³ ì„œ ì´ˆì•ˆ ìƒì„± ì‹œì‘")

        topic = state["topic"]
        outline = state["outline"]
        section_headers = re.findall(r"^(#+ .*)$", outline, re.MULTILINE)
        self.logger.add_log("INFO", f"ì´ {len(section_headers)}ê°œ ì„¹ì…˜ ìƒì„± ì˜ˆì •")

        report_content = {}
        for i, header in enumerate(section_headers):
            progress_msg = f"ì´ˆì•ˆ ìƒì„± ì¤‘({i+1}/{len(section_headers)}): {header}"
            self.logger.add_log("INFO", progress_msg)
            self.root.title(progress_msg)
            self.root.update_idletasks()
            report_content[header] = self._generate_single_section(header, topic)

        current_report_text = "\n\n".join(
            [f"{header}\n{text}" for header, text in report_content.items()]
        )
        self.logger.add_log(
            "SUCCESS", f"ì´ˆì•ˆ ìƒì„± ì™„ë£Œ (ì´ ê¸¸ì´: {len(current_report_text)}ì)"
        )

        return {
            "report_content": report_content,
            "current_report_text": current_report_text,
            "progress_message": "2/6: ì´ˆì•ˆ ìƒì„± ì™„ë£Œ. í¸ì§‘ì¥ ê²€í†  ì‹œì‘...",
        }

    def node_editorial_review(self, state: ReportState):
        """í¸ì§‘ì¥ ê²€í†  ë…¸ë“œ"""
        self.logger.set_current_node("editorial_review")
        self.logger.add_log("INFO", "[3/6] í¸ì§‘ì¥ ê²€í†  ë° ê°œì„  ì‘ì—… ì‹œì‘")

        current_report_text = state["current_report_text"]
        outline = state["outline"]
        review_attempts = state["review_attempts"] + 1

        self.logger.add_log(
            "INFO", f"í¸ì§‘ì¥ ê²€í†  ì‹œë„ ({review_attempts}/{MAX_REVIEW_ATTEMPTS})"
        )
        self.root.title(
            f"í¸ì§‘ì¥ ê²€í† ... (ì‹œë„ {review_attempts}/{MAX_REVIEW_ATTEMPTS})"
        )
        self.root.update_idletasks()

        review_result = self._editorial_review_logic(current_report_text, outline)
        review_history = state["review_history"] + [
            {"attempt": review_attempts, "result": review_result}
        ]

        # ê²€í†  ê²°ê³¼ ë¡œê¹…
        if review_result.get("review_passed", True):
            self.logger.add_log("SUCCESS", "í¸ì§‘ì¥ ê²€í†  í†µê³¼")
        else:
            sections_to_improve = review_result.get("sections_to_improve", [])
            self.logger.add_log(
                "WARNING",
                f"í¸ì§‘ì¥ ê²€í†  ê²°ê³¼: {len(sections_to_improve)}ê°œ ì„¹ì…˜ ê°œì„  í•„ìš”",
            )
            for section in sections_to_improve:
                self.logger.add_log(
                    "WARNING",
                    f"  - ê°œì„  í•„ìš”: {section.get('section_header', 'Unknown')}",
                )

        return {
            "review_result": review_result,
            "review_history": review_history,
            "review_attempts": review_attempts,
            "progress_message": f"3/6: í¸ì§‘ì¥ ê²€í†  {review_attempts}ì°¨ ì™„ë£Œ.",
        }

    def node_regenerate_sections(self, state: ReportState):
        """ê²€í†  ê²°ê³¼ì— ë”°ë¼ ì„¹ì…˜ ì¬ì‘ì„± ë…¸ë“œ"""
        self.logger.set_current_node("regenerate_sections")

        review_result = state["review_result"]
        sections_to_improve = review_result.get("sections_to_improve", [])
        self.logger.add_log("INFO", f"í¸ì§‘ì¥ ê°œì„  ìš”ì²­: {len(sections_to_improve)}ê°œ ì„¹ì…˜ ì¬ì‘ì„± í•„ìš”")

        topic = state["topic"]
        report_content = state["report_content"].copy()
        
        regenerated_count = 0
        for i, section_data in enumerate(sections_to_improve):
            header = section_data.get("section_header")
            instructions = section_data.get("how_to_improve")
            
            # ì—¬ëŸ¬ í˜•ì‹ì˜ í—¤ë”(###, #### ë“±)ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì •ê·œì‹ìœ¼ë¡œ ì°¾ê¸°
            matching_headers = [h for h in report_content.keys() if header.strip().endswith(h.strip('# ').strip())]
            
            if matching_headers:
                actual_header = matching_headers[0]
                progress_msg = f"ì¬ì‘ì„± ì¤‘({i+1}/{len(sections_to_improve)}): {actual_header}"
                self.logger.add_log("INFO", progress_msg)
                self.root.title(progress_msg)
                self.root.update_idletasks()
                
                # _generate_single_sectionì„ í˜¸ì¶œí•˜ì—¬ ì‹¤ì œë¡œ ì¬ì‘ì„± ìˆ˜í–‰
                report_content[actual_header] = self._generate_single_section(
                    actual_header, topic, improvement_instructions=instructions
                )
                regenerated_count += 1
            else:
                self.logger.add_log("WARNING", f"ì¬ì‘ì„± ëŒ€ìƒ ì„¹ì…˜ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: '{header}'")


        current_report_text = "\n\n".join(
            [f"{h}\n{t}" for h, t in report_content.items()]
        )

        self.logger.add_log("SUCCESS", f"{regenerated_count}ê°œ ì„¹ì…˜ ì¬ì‘ì„± ì™„ë£Œ")

        return {
            "report_content": report_content,
            "current_report_text": current_report_text,
            "progress_message": f"ê°œì„  ìš”ì²­ëœ {len(sections_to_improve)}ê°œ ì„¹ì…˜ ì¬ì‘ì„± ì™„ë£Œ. ë‹¤ì‹œ í¸ì§‘ì¥ ê²€í† ë¥¼ ë°›ìŠµë‹ˆë‹¤.",
        }

    def node_final_formatting(self, state: ReportState):
        """ìµœì¢… ì„œì‹ ì •ë¦¬ ë…¸ë“œ"""
        self.logger.set_current_node("final_formatting")
        self.logger.add_log("INFO", "[4/6] ìµœì¢… ê°€ë…ì„± í–¥ìƒì„ ìœ„í•œ ì„œì‹ ì •ë¦¬ ì‹œì‘")

        current_report_text = state["current_report_text"]
        self.logger.add_log(
            "INFO", f"ì„œì‹ ì •ë¦¬ ì „ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(current_report_text)}ì"
        )

        formatted_report = self._final_formatting_logic(current_report_text)
        self.logger.add_log(
            "SUCCESS", f"ì„œì‹ ì •ë¦¬ ì™„ë£Œ (ìµœì¢… ê¸¸ì´: {len(formatted_report)}ì)"
        )

        return {
            "formatted_report": formatted_report,
            "progress_message": "4/6: ì„œì‹ ì •ë¦¬ ì™„ë£Œ. ê°ì£¼ ì²˜ë¦¬ ì‹œì‘...",
        }

    def node_finalize_citations_and_save_log(self, state: ReportState):
        """ê°ì£¼ ì²˜ë¦¬ ë° ê²€í†  ë¡œê·¸ ì €ì¥ ë…¸ë“œ"""
        self.logger.set_current_node("finalize_and_save")
        self.logger.add_log(
            "INFO", "[5/6] ìµœì¢… ê°ì£¼ ë²ˆí˜¸ ë¶€ì—¬ ë° ì°¸ê³ ë¬¸í—Œ ëª©ë¡ ìƒì„± ì‹œì‘"
        )

        formatted_report = state["formatted_report"]
        final_report_body, references_list = self._finalize_citations_logic(
            formatted_report
        )
        final_report_with_refs = final_report_body + references_list

        # ì°¸ê³ ë¬¸í—Œ í†µê³„ ë¡œê¹…
        ref_count = references_list.count("[^") if references_list else 0
        self.logger.add_log("INFO", f"ìµœì¢… ì°¸ê³ ë¬¸í—Œ ê°œìˆ˜: {ref_count}ê°œ")

        # í¸ì§‘ì¥ ê²€í†  ê¸°ë¡ ì €ì¥
        now = datetime.now()
        date_str = now.strftime("%Y%m%d_%H%M%S")
        review_log_filename = f"editorial_review_log_{date_str}.md"
        # ê²°ê³¼ í´ë”ì— ì €ì¥í•˜ê¸° ìœ„í•´ ê²½ë¡œ ìƒì„± (self.results_folderëŠ” run_generation_in_threadì—ì„œ ì„¤ì •ë¨)
        if hasattr(self, "results_folder") and self.results_folder:
            review_log_path = os.path.join(self.results_folder, review_log_filename)
        else:
            review_log_path = review_log_filename

        self.logger.add_log(
            "INFO", f"í¸ì§‘ì¥ ê²€í†  ê¸°ë¡ì„ '{review_log_path}' íŒŒì¼ë¡œ ì €ì¥ ì¤‘"
        )

        with open(review_log_path, "w", encoding="utf-8") as f:
            f.write(f"# í¸ì§‘ì¥ ê²€í†  ê¸°ë¡ ({date_str})\n\n")

            # ì‚¬ìš©ëœ AI ëª¨ë¸ ì •ë³´ ì¶”ê°€
            f.write("## ì‚¬ìš©ëœ AI ëª¨ë¸\n\n")
            model_names = {
                "outline_generation": "ê°œìš” ìƒì„±",
                "draft_generation": "ì´ˆì•ˆ ìƒì„±",
                "editorial_review": "í¸ì§‘ì¥ ê²€í† ",
                "final_formatting": "ìµœì¢… ì„œì‹ ì •ë¦¬",
            }
            for task, model in self.models.items():
                task_name = model_names.get(task, task)
                f.write(f"- **{task_name}:** `{model}`\n")
            f.write("\n")

            # ì°¸ê³ ë¬¸í—Œ í†µê³„ ì •ë³´ ì¶”ê°€
            total_chunks = len(self.db_data) if self.db_data else 0
            with_references = len(self.chunk_id_map) if self.chunk_id_map else 0
            f.write(f"## ì°¸ê³ ë¬¸í—Œ í†µê³„\n\n")
            f.write(f"- ì „ì²´ ë°ì´í„° ì²­í¬: {total_chunks}ê°œ\n")
            f.write(f"- ì°¸ê³ ë¬¸í—Œ ìˆëŠ” ì²­í¬: {with_references}ê°œ\n")
            f.write(f"- ì°¸ê³ ë¬¸í—Œ ë¹„ìœ¨: {with_references/total_chunks*100:.1f}%\n\n")

            # ìµœì¢… ë³´ê³ ì„œì˜ ì°¸ê³ ë¬¸í—Œ ê°œìˆ˜
            f.write(f"- ìµœì¢… ë³´ê³ ì„œ ì°¸ê³ ë¬¸í—Œ ê°œìˆ˜: {ref_count}ê°œ\n\n")

            for item in state["review_history"]:
                f.write(f"## ê²€í†  ì‹œë„ #{item['attempt']}\n\n")
                result = item["result"]
                if result.get("review_passed", True) or not result.get(
                    "sections_to_improve"
                ):
                    f.write("**ê²°ê³¼:** ğŸŸ¢ ìŠ¹ì¸ë¨\n\n")
                else:
                    f.write("**ê²°ê³¼:** ğŸ”´ ê°œì„  í•„ìš”\n\n")
                    f.write("### ê°œì„  ìš”ì²­ ì‚¬í•­:\n\n")
                    for i, sec in enumerate(result["sections_to_improve"]):
                        f.write(f"**{i+1}. ì„¹ì…˜:** `{sec.get('section_header')}`\n")
                        f.write(f"   - **ë¬¸ì œì :** {sec.get('reason')}\n")
                        f.write(f"   - **ê°œì„  ì§€ì¹¨:** {sec.get('how_to_improve')}\n\n")

        self.logger.add_log("SUCCESS", f"í¸ì§‘ì¥ ê²€í†  ê¸°ë¡ ì €ì¥ ì™„ë£Œ: {review_log_path}")

        return {
            "final_report_with_refs": final_report_with_refs,
            "progress_message": "5/6: ê°ì£¼ ì²˜ë¦¬ ë° ë¡œê·¸ ì €ì¥ ì™„ë£Œ. ìµœì¢… íŒŒì¼ ì €ì¥ ì¤€ë¹„...",
        }

    # =============================================================================
    # LangGraph ì¡°ê±´ë¶€ ì—£ì§€
    # =============================================================================
    def should_continue_review(self, state: ReportState):
        """í¸ì§‘ì¥ ê²€í† ë¥¼ ê³„ì†í• ì§€ ê²°ì •í•˜ëŠ” ì¡°ê±´ë¶€ ì—£ì§€"""
        review_result = state["review_result"]
        review_attempts = state["review_attempts"]

        if review_result.get("review_passed", True) or not review_result.get(
            "sections_to_improve"
        ):
            print("  - í¸ì§‘ì¥ ê²€í†  ê²°ê³¼: í†µê³¼. ê°œì„  ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return "end_review"

        if review_attempts >= MAX_REVIEW_ATTEMPTS:
            print(
                f"  - ìµœëŒ€ ê²€í†  íšŸìˆ˜({MAX_REVIEW_ATTEMPTS})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ê°œì„ ì„ ì¤‘ë‹¨í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤."
            )
            return "end_review"

        return "regenerate"

    # =============================================================================
    # LangGraph ë¹Œë“œ ë° ì‹¤í–‰
    # =============================================================================
    def _build_graph(self):
        """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        workflow = StateGraph(ReportState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("generate_outline", self.node_generate_outline)
        workflow.add_node("generate_draft", self.node_generate_draft)
        workflow.add_node("editorial_review", self.node_editorial_review)
        workflow.add_node("regenerate_sections", self.node_regenerate_sections)
        workflow.add_node("final_formatting", self.node_final_formatting)
        workflow.add_node(
            "finalize_and_save", self.node_finalize_citations_and_save_log
        )

        # ì—£ì§€ ì—°ê²°
        workflow.set_entry_point("generate_outline")
        workflow.add_edge("generate_outline", "generate_draft")
        workflow.add_edge("generate_draft", "editorial_review")

        # ì¡°ê±´ë¶€ ì—£ì§€ (í¸ì§‘ì¥ ê²€í†  ë£¨í”„)
        workflow.add_conditional_edges(
            "editorial_review",
            self.should_continue_review,
            {"regenerate": "regenerate_sections", "end_review": "final_formatting"},
        )
        workflow.add_edge("regenerate_sections", "editorial_review")

        workflow.add_edge("final_formatting", "finalize_and_save")
        workflow.add_edge("finalize_and_save", END)

        return workflow.compile()

    def run_generation_pipeline(self):
        """GUIì—ì„œ í˜¸ì¶œë˜ëŠ” ì‹œì‘ ë©”ì„œë“œì…ë‹ˆë‹¤."""
        topic = self.topic_entry.get().strip()
        if not topic:
            messagebox.showwarning("ì…ë ¥ ì˜¤ë¥˜", "ë³´ê³ ì„œ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        self.generate_button.config(state="disabled")
        self.visualization_button.config(state="disabled")
        self.log_button.config(state="disabled")
        self._update_status("ë³´ê³ ì„œ ìƒì„± ì‹œì‘...", "blue")

        threading.Thread(
            target=self.run_generation_in_thread, args=(topic,), daemon=True
        ).start()

    def process_queue(self):
        """íë¥¼ í™•ì¸í•˜ì—¬ GUI ì—…ë°ì´íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            message = self.progress_queue.get_nowait()
            if "progress_message" in message:
                self.root.title(message["progress_message"])
                self._update_status(message["progress_message"], "blue")
            if "final_report" in message:
                # ìµœì¢… ë³´ê³ ì„œ ì²˜ë¦¬ ë¡œì§
                self._show_report(message["final_report"])
                messagebox.showinfo("ìƒì„± ì™„ë£Œ", "ë¦¬í¬íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                self._update_status("ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ", "green")
            if "error" in message:
                messagebox.showerror("ì˜¤ë¥˜", message["error"])
                self._update_status("ì˜¤ë¥˜ ë°œìƒ", "red")
            if "generation_done" in message:
                self.generate_button.config(state="normal")
                # ë²„íŠ¼ í™œì„±í™” ë° ìµœì‹  íŒŒì¼ ê²½ë¡œ ì—…ë°ì´íŠ¸
                self._update_buttons_after_generation()

        except queue.Empty:
            pass
        finally:
            self.root.after(100, self.process_queue)

    def _update_buttons_after_generation(self):
        """ìƒì„± ì™„ë£Œ í›„ ë²„íŠ¼ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        try:
            # ê°€ì¥ ìµœê·¼ ìƒì„±ëœ ê²°ê³¼ í´ë” ì°¾ê¸°
            result_folders = [
                f
                for f in os.listdir(".")
                if f.startswith("results_") and os.path.isdir(f)
            ]

            if result_folders:
                result_folders.sort(reverse=True)  # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
                latest_result_folder = result_folders[0]

                # ì‹œê°í™” íŒŒì¼ ì°¾ê¸°
                viz_folder = os.path.join(latest_result_folder, "visualizations")
                if os.path.exists(viz_folder):
                    dashboard_files = [
                        f
                        for f in os.listdir(viz_folder)
                        if f.startswith("dashboard_") and f.endswith(".png")
                    ]
                    if dashboard_files:
                        dashboard_files.sort(reverse=True)
                        self.latest_dashboard_path = os.path.join(
                            viz_folder, dashboard_files[0]
                        )
                        self.visualization_button.config(state="normal")

                # ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
                logs_folder = os.path.join(latest_result_folder, "logs")
                if os.path.exists(logs_folder):
                    log_files = [
                        f
                        for f in os.listdir(logs_folder)
                        if f.startswith("pipeline_log_") and f.endswith(".md")
                    ]
                    if log_files:
                        log_files.sort(reverse=True)
                        self.latest_log_path = os.path.join(logs_folder, log_files[0])
                        self.log_button.config(state="normal")

        except Exception as e:
            print(f"ë²„íŠ¼ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")

    def run_generation_in_thread(self, topic):
        """ì‹¤ì œ ìƒì„± ë¡œì§ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            # ì‹¤í–‰ ëª¨ë“œì— ë”°ë¼ ëª¨ë¸ ì„¤ì •
            mode = self.mode_var.get()
            if mode == "Production":
                self.models = PRODUCTION_MODELS
                self.thinking_budgets = PRODUCTION_THINKING_BUDGETS
            else:
                self.models = TEST_MODELS
                self.thinking_budgets = TEST_THINKING_BUDGETS

            # ë¡œê¹… ì„¸ì…˜ ì‹œì‘ ë° ê²°ê³¼ í´ë” ìƒì„±
            session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.results_folder = f"results_{mode.lower()}_{session_id}"
            self.logs_folder = os.path.join(self.results_folder, "logs")
            self.viz_folder = os.path.join(self.results_folder, "visualizations")

            # í´ë” ìƒì„±
            os.makedirs(self.results_folder, exist_ok=True)
            os.makedirs(self.logs_folder, exist_ok=True)
            os.makedirs(self.viz_folder, exist_ok=True)

            self.logger.start_logging(session_id)
            self.logger.add_log(
                "SYSTEM", "=" * 20 + " ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘ " + "=" * 20
            )

            initial_state = {
                "topic": topic,
                "outline": "",
                "report_content": {},
                "current_report_text": "",
                "review_result": {},
                "review_history": [],
                "review_attempts": 0,
                "formatted_report": "",
                "final_report_with_refs": "",
                "progress_message": "0/6: íŒŒì´í”„ë¼ì¸ ì‹œì‘...",
            }

            final_state = None
            # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ê·¸ë˜í”„ ì‹¤í–‰ ë° ê° ë‹¨ê³„ë³„ ìƒíƒœ ì¶œë ¥
            for event in self.graph.stream(initial_state, {"recursion_limit": 15}):
                node_name = list(event.keys())[0]
                node_output = event[node_name]

                # ìƒíƒœ ì—…ë°ì´íŠ¸ ë‚´ìš© ì¶œë ¥ (ë¯¼ê° ì •ë³´ë‚˜ ë„ˆë¬´ ê¸´ ë‚´ìš©ì€ ìƒëµ)
                for key, value in node_output.items():
                    if isinstance(value, str) and len(value) > 300:
                        self.logger.add_log("DEBUG", f"  - {key}: (ë‚´ìš©ì´ ê¸¸ì–´ ìƒëµë¨)")
                    elif key not in ["client", "root"]:
                        self.logger.add_log("DEBUG", f"  - {key}: {value}")

                # UI ì—…ë°ì´íŠ¸ëŠ” íë¥¼ í†µí•´ ì „ë‹¬
                if (
                    "progress_message" in node_output
                    and node_output["progress_message"]
                ):
                    self.progress_queue.put(
                        {"progress_message": node_output["progress_message"]}
                    )

                # ë§ˆì§€ë§‰ ì‹¤í–‰ëœ ë…¸ë“œì˜ ìƒíƒœë¥¼ final_stateë¡œ ì €ì¥
                final_state = node_output

            self.logger.add_log(
                "SYSTEM", "=" * 20 + " ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ " + "=" * 20
            )

            if not final_state:
                raise Exception("ê·¸ë˜í”„ ì‹¤í–‰ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            final_report_with_refs = final_state.get(
                "final_report_with_refs", "ì˜¤ë¥˜: ìµœì¢… ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

            # íŒŒì¼ ì €ì¥
            now = datetime.now()
            date_str = now.strftime("%Y%m%d_%H%M%S")
            report_filename = os.path.join(
                self.results_folder, f"final_report_{date_str}.md"
            )
            self.logger.add_log(
                "INFO", f"[6/6] ë³´ê³ ì„œ íŒŒì¼ ì €ì¥ ì¤‘... -> '{report_filename}'"
            )

            # ìµœì¢… í†µê³„ ì •ë³´ ì¶œë ¥
            ref_count = (
                final_report_with_refs.count("[^") if final_report_with_refs else 0
            )
            word_count = (
                len(final_report_with_refs.split()) if final_report_with_refs else 0
            )
            self.logger.add_log("INFO", f"ìµœì¢… ë³´ê³ ì„œ í†µê³„:")
            self.logger.add_log("INFO", f"  * ì´ ë‹¨ì–´ ìˆ˜: {word_count}ê°œ")
            self.logger.add_log("INFO", f"  * ì°¸ê³ ë¬¸í—Œ ìˆ˜: {ref_count}ê°œ")
            self.logger.add_log(
                "INFO",
                f"  * íŒŒì¼ í¬ê¸°: {len(final_report_with_refs.encode('utf-8'))} bytes",
            )

            with open(report_filename, "w", encoding="utf-8") as f:
                f.write(final_report_with_refs)

            # ë¡œê·¸ íŒŒì¼ ì €ì¥
            full_log_path, node_log_paths = self.logger.save_logs(self.logs_folder)
            self.logger.add_log("SUCCESS", f"ì „ì²´ ë¡œê·¸ íŒŒì¼: {full_log_path}")
            self.logger.add_log("SUCCESS", f"ë…¸ë“œë³„ ë¡œê·¸ íŒŒì¼: {len(node_log_paths)}ê°œ")
            self.latest_log_path = full_log_path  # ê²½ë¡œ ì €ì¥

            # ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ìƒì„±
            self.logger.add_log("INFO", "ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
            try:
                dashboard_path = self.analyzer.create_visualization_dashboard(
                    self.logger, final_state, self.viz_folder
                )
                if dashboard_path:
                    self.logger.add_log(
                        "SUCCESS", f"ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ: {dashboard_path}"
                    )
                    self.latest_dashboard_path = dashboard_path  # ê²½ë¡œ ì €ì¥
                else:
                    self.logger.add_log("WARNING", "ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ìƒì„± ì‹¤íŒ¨")
            except Exception as e:
                self.logger.add_log("ERROR", f"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

            # ê²°ê³¼ í´ë” ì •ë³´ ë¡œê·¸
            self.logger.add_log("SUCCESS", f"=" * 50)
            self.logger.add_log("SUCCESS", f"ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            self.logger.add_log("SUCCESS", f"ğŸ“ ê²°ê³¼ í´ë”: {self.results_folder}")
            self.logger.add_log(
                "SUCCESS", f"   ğŸ“„ ë³´ê³ ì„œ: {os.path.basename(report_filename)}"
            )
            self.logger.add_log("SUCCESS", f"   ğŸ“Š ì‹œê°í™”: visualizations/")
            self.logger.add_log("SUCCESS", f"   ğŸ“‹ ë¡œê·¸: logs/")
            self.logger.add_log("SUCCESS", f"=" * 50)

            # ìµœì¢… ê²°ê³¼ ì „ë‹¬
            self.progress_queue.put({"final_report": final_report_with_refs})

        except Exception as e:
            import traceback

            traceback.print_exc()
            self.logger.add_log("ERROR", f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.progress_queue.put({"error": f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"})
        finally:
            self.progress_queue.put(
                {
                    "progress_message": "RAG ë¦¬í¬íŠ¸ ìƒì„±ê¸° v4 (ì§€ëŠ¥í˜•)",
                    "generation_done": True,
                }
            )

    def _show_report(self, report_text):
        report_window = tk.Toplevel(self.root)
        report_window.title("ìƒì„±ëœ ë¦¬í¬íŠ¸ (v4)")
        report_window.geometry("800x600")
        text_area = scrolledtext.ScrolledText(
            report_window, wrap=tk.WORD, font=("ë§‘ì€ ê³ ë”•", 10)
        )
        text_area.insert(tk.INSERT, report_text)
        text_area.pack(expand=True, fill="both", padx=10, pady=10)
        text_area.configure(state="disabled")

    def show_latest_visualization(self):
        """ìµœê·¼ ìƒì„±ëœ ì‹œê°í™” ëŒ€ì‹œë³´ë“œë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
        if not self.latest_dashboard_path or not os.path.exists(
            self.latest_dashboard_path
        ):
            messagebox.showwarning("ì•Œë¦¼", "í‘œì‹œí•  ì‹œê°í™” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        try:
            # ìƒˆ ì°½ì—ì„œ ì‹œê°í™” í‘œì‹œ
            viz_window = tk.Toplevel(self.root)
            viz_window.title("ì‹œê°í™” ëŒ€ì‹œë³´ë“œ")
            viz_window.geometry("1200x800")

            # ì´ë¯¸ì§€ ë¡œë“œ ë° í‘œì‹œ
            from PIL import Image, ImageTk

            img = Image.open(self.latest_dashboard_path)

            # ì°½ í¬ê¸°ì— ë§ê²Œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            img_width, img_height = img.size
            max_width, max_height = 1150, 750

            if img_width > max_width or img_height > max_height:
                img.thumbnail((max_width, max_height), Image.Resampling.LANCZOS)

            photo = ImageTk.PhotoImage(img)

            # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ìº”ë²„ìŠ¤ ìƒì„±
            canvas = tk.Canvas(viz_window, scrollregion=(0, 0, img.width, img.height))
            canvas.pack(fill=tk.BOTH, expand=True)

            # ì´ë¯¸ì§€ í‘œì‹œ
            canvas.create_image(0, 0, anchor=tk.NW, image=photo)
            canvas.image = photo  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë°©ì§€

            # ìŠ¤í¬ë¡¤ë°” ì¶”ê°€
            scrollbar_v = tk.Scrollbar(
                viz_window, orient=tk.VERTICAL, command=canvas.yview
            )
            scrollbar_v.pack(side=tk.RIGHT, fill=tk.Y)
            canvas.configure(yscrollcommand=scrollbar_v.set)

            scrollbar_h = tk.Scrollbar(
                viz_window, orient=tk.HORIZONTAL, command=canvas.xview
            )
            scrollbar_h.pack(side=tk.BOTTOM, fill=tk.X)
            canvas.configure(xscrollcommand=scrollbar_h.set)

        except Exception as e:
            messagebox.showerror("ì˜¤ë¥˜", f"ì‹œê°í™” í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            # PILì´ ì—†ëŠ” ê²½ìš° ëŒ€ì•ˆ
            try:
                import webbrowser

                webbrowser.open(self.latest_dashboard_path)
            except:
                messagebox.showinfo(
                    "ì•Œë¦¼",
                    f"ì‹œê°í™” íŒŒì¼ì„ ì§ì ‘ ì—´ì–´ë³´ì„¸ìš”:\n{self.latest_dashboard_path}",
                )

    def show_log_files(self):
        """ë¡œê·¸ íŒŒì¼ ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
        try:
            # ë¡œê·¸ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìƒˆë¡œìš´ í´ë” êµ¬ì¡°)
            log_files = []

            # ê²°ê³¼ í´ë”ë“¤ ìŠ¤ìº”
            for folder in os.listdir("."):
                if folder.startswith("results_") and os.path.isdir(folder):
                    logs_folder = os.path.join(folder, "logs")
                    if os.path.exists(logs_folder):
                        for file in os.listdir(logs_folder):
                            if (
                                file.startswith("pipeline_log_")
                                or file.startswith("node_")
                            ) and file.endswith(".md"):
                                log_files.append(os.path.join(logs_folder, file))

            # ê¸°ì¡´ ë£¨íŠ¸ í´ë”ì˜ ë¡œê·¸ íŒŒì¼ë“¤ë„ í™•ì¸ (í•˜ìœ„ í˜¸í™˜ì„±)
            for file in os.listdir("."):
                if (
                    file.startswith("pipeline_log_") or file.startswith("node_")
                ) and file.endswith(".md"):
                    log_files.append(file)

            if not log_files:
                messagebox.showinfo("ì•Œë¦¼", "ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            # ë¡œê·¸ íŒŒì¼ ì„ íƒ ì°½
            log_window = tk.Toplevel(self.root)
            log_window.title("ë¡œê·¸ íŒŒì¼ ëª©ë¡")
            log_window.geometry("600x400")

            tk.Label(
                log_window, text="ë¡œê·¸ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:", font=("Arial", 12)
            ).pack(pady=10)

            # ë¦¬ìŠ¤íŠ¸ë°•ìŠ¤ ìƒì„±
            listbox = tk.Listbox(log_window, font=("Consolas", 10))
            listbox.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

            # ë¡œê·¸ íŒŒì¼ ëª©ë¡ ì¶”ê°€ (ìµœì‹  ìˆœ)
            log_files.sort(reverse=True)
            for file in log_files:
                listbox.insert(tk.END, file)

            # íŒŒì¼ ì—´ê¸° ë²„íŠ¼
            def open_selected_log():
                selection = listbox.curselection()
                if selection:
                    selected_file = listbox.get(selection[0])
                    self._open_log_file(selected_file)

            tk.Button(
                log_window, text="ë¡œê·¸ íŒŒì¼ ì—´ê¸°", command=open_selected_log
            ).pack(pady=10)

        except Exception as e:
            messagebox.showerror("ì˜¤ë¥˜", f"ë¡œê·¸ íŒŒì¼ ëª©ë¡ í‘œì‹œ ì¤‘ ì˜¤ë¥˜: {e}")

    def _open_log_file(self, filename):
        """ë¡œê·¸ íŒŒì¼ì„ ìƒˆ ì°½ì—ì„œ í‘œì‹œí•©ë‹ˆë‹¤."""
        try:
            with open(filename, "r", encoding="utf-8") as f:
                content = f.read()

            # ìƒˆ ì°½ì—ì„œ ë¡œê·¸ ë‚´ìš© í‘œì‹œ
            log_content_window = tk.Toplevel(self.root)
            log_content_window.title(f"ë¡œê·¸ ë‚´ìš©: {filename}")
            log_content_window.geometry("900x700")

            # í…ìŠ¤íŠ¸ ì—ë¦¬ì–´ ìƒì„±
            text_area = scrolledtext.ScrolledText(
                log_content_window, wrap=tk.WORD, font=("Consolas", 9)
            )
            text_area.insert(tk.INSERT, content)
            text_area.pack(expand=True, fill="both", padx=10, pady=10)
            text_area.configure(state="disabled")

        except Exception as e:
            messagebox.showerror("ì˜¤ë¥˜", f"ë¡œê·¸ íŒŒì¼ ì—´ê¸° ì¤‘ ì˜¤ë¥˜: {e}")

    def _update_status(self, message, color="black"):
        """ìƒíƒœ ë¼ë²¨ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        self.status_label.config(text=message, fg=color)
        self.root.update_idletasks()


if __name__ == "__main__":
    root = tk.Tk()
    app = RAGReportGeneratorAppV3(root)
    root.mainloop()

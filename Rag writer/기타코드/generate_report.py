import os
import google.generativeai as genai
from google.generativeai import types
from dotenv import load_dotenv
import re
import json
from datetime import datetime
import argparse

# =============================================================================
# ëª¨ë¸ ì„¤ì • êµ¬ì„± (í…ŒìŠ¤íŠ¸/í”„ë¡œë•ì…˜ í™˜ê²½ì— ë”°ë¼ ì¡°ì •)
# =============================================================================

# ì €ë ´í•œ ëª¨ë¸ë“¤ë¡œ í…ŒìŠ¤íŠ¸í•  ë•Œ ì‚¬ìš©
TEST_MODELS = {
    "outline_generation": "gemini-2.5-flash-lite-preview-06-17",  # ê°œìš” ìƒì„±
    "content_analysis": "gemini-2.5-flash-lite-preview-06-17",  # ì½˜í…ì¸  ë¶„ì„ (ì¤‘ë³µ ê²€ì‚¬ ë“±)
    "draft_generation": "gemini-2.5-flash-lite-preview-06-17",  # ì´ˆì•ˆ ìƒì„±
    "editorial_review": "gemini-2.5-flash-lite-preview-06-17",  # í¸ì§‘ì¥ ê²€í† 
    "quality_check": "gemini-2.5-flash-lite-preview-06-17",  # í’ˆì§ˆ ê²€ì‚¬
    "reference_extraction": "gemini-2.5-flash-lite-preview-06-17",  # ì°¸ê³ ë¬¸í—Œ ì¶”ì¶œ
}

# í”„ë¡œë•ì…˜ì—ì„œ ì‚¬ìš©í•  ê³ ê¸‰ ëª¨ë¸ë“¤
PRODUCTION_MODELS = {
    "outline_generation": "gemini-2.5-pro",
    "content_analysis": "gemini-2.5-pro",
    "draft_generation": "gemini-2.5-pro",
    "editorial_review": "gemini-2.5-pro",
    "quality_check": "gemini-2.5-pro",
    "reference_extraction": "gemini-2.5-pro",
}

# =============================================================================
# Thinking Budget ì„¤ì •
# =============================================================================

# í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œëŠ” ëª¨ë“  ì‘ì—…ì— thinking_budgetì„ 0ìœ¼ë¡œ ì„¤ì •
TEST_THINKING_BUDGETS = {
    "outline_generation": 0,
    "content_analysis": 0,
    "draft_generation": 0,
    "editorial_review": 0,
    "quality_check": 0,
    "reference_extraction": 0,
}

# í”„ë¡œë•ì…˜ ëª¨ë“œì—ì„œëŠ” í¸ì§‘ì¥ ê²€í† ì™€ í’ˆì§ˆ ê²€ì‚¬ë¥¼ ì œì™¸í•˜ê³  0ìœ¼ë¡œ ì„¤ì •
PRODUCTION_THINKING_BUDGETS = {
    "outline_generation": 0,
    "content_analysis": 0,
    "draft_generation": 0,
    "editorial_review": 8192,  # Noneì€ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•˜ë„ë¡ í•¨
    "quality_check": 8192,  # Noneì€ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•˜ë„ë¡ í•¨
    "reference_extraction": 0,
}

# ì‚¬ìš©í•  ëª¨ë¸ ì„¸íŠ¸ ì„ íƒ (True: í”„ë¡œë•ì…˜, False: í…ŒìŠ¤íŠ¸)
USE_PRODUCTION_MODELS = True

# í˜„ì¬ ì‚¬ìš©í•  ëª¨ë¸ ë° ì˜ˆì‚° ì„¤ì •
CURRENT_MODELS = PRODUCTION_MODELS if USE_PRODUCTION_MODELS else TEST_MODELS
CURRENT_BUDGETS = (
    PRODUCTION_THINKING_BUDGETS if USE_PRODUCTION_MODELS else TEST_THINKING_BUDGETS
)

# ê°œë³„ ì‘ì—…ë³„ ëª¨ë¸ ì˜¤ë²„ë¼ì´ë“œ (í•„ìš”ì‹œ íŠ¹ì • ì‘ì—…ë§Œ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©)
MODEL_OVERRIDES = {
    # ì˜ˆ: 'outline_generation': 'gemini-2.5-pro',  # ê°œìš” ìƒì„±ë§Œ ê³ ê¸‰ ëª¨ë¸ ì‚¬ìš©
    # ì˜ˆ: 'quality_check': 'gemini-2.5-pro',       # í’ˆì§ˆ ê²€ì‚¬ë§Œ ê³ ê¸‰ ëª¨ë¸ ì‚¬ìš©
}

# ìµœì¢… ëª¨ë¸ ì„¤ì • (ì˜¤ë²„ë¼ì´ë“œ ì ìš©)
MODELS = {**CURRENT_MODELS, **MODEL_OVERRIDES}
THINKING_BUDGETS = {**CURRENT_BUDGETS}

# =============================================================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒìˆ˜
# =============================================================================
# ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œë„ ì¬í™œìš©í•  ìˆ˜ ìˆë„ë¡, ê°œìš” ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼
# ë³„ë„ì˜ ìƒìˆ˜ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤. `{content}` í”Œë ˆì´ìŠ¤í™€ë”ì— í†µí•© ë¬¸ì„œ ë‚´ìš©ì´
# ì‚½ì…ë©ë‹ˆë‹¤.
OUTLINE_PROMPT_TEMPLATE = """
ë‹¤ìŒì€ 'ì‚¬ë‚´ ë³€í˜¸ì‚¬ì˜ ë¹„ë°€ìœ ì§€ê¶Œ'ì— ëŒ€í•œ ì—¬ëŸ¬ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ í•©ì¹œ ë‚´ìš©ì…ë‹ˆë‹¤.
ì´ ì „ì²´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, í•˜ë‚˜ì˜ ì¼ê´€ëœ íë¦„ì„ ê°–ëŠ” ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
ë³´ê³ ì„œì˜ ìƒˆë¡œìš´ í•µì‹¬ ì£¼ì œëŠ” "ì‚¬ë‚´ ë³€í˜¸ì‚¬ë¥¼ ìœ„í•œ ACPì˜ êµ­ë‚´ ë„ì…ì„ ìœ„í•œ ìœ ëŸ½ ì‚¬ë¡€ ì—°êµ¬ì¡°ì‚¬" ì…ë‹ˆë‹¤.

**ì§€ì‹œì‚¬í•­:**
1.  **ìœ ëŸ½ ì¤‘ì‹¬ ì¬êµ¬ì„±:** ë³´ê³ ì„œì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ìœ ëŸ½ì˜ ì‚¬ë¡€(EU, ë…ì¼, í”„ë‘ìŠ¤ ë“±)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”.
2.  **í¬ê´„ì„± ë° ë‚´ìš© ë³´ì¡´:** **ê°€ì¥ ì¤‘ìš”í•œ ì ì…ë‹ˆë‹¤.** ì›ë³¸ ë¬¸ì„œì˜ ëª¨ë“  í•µì‹¬ì ì¸ ë‚´ìš©(ë‹¤ë¥¸ êµ­ê°€, ì´ë¡ ì  ë°°ê²½ ë“±)ì´ ìµœì¢… ë³´ê³ ì„œì—ì„œ ì ˆëŒ€ ì†Œì‹¤ë˜ì§€ ì•Šë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤. ìœ ëŸ½ ì™¸ êµ­ê°€ì˜ ì •ë³´ëŠ” ìœ ëŸ½ ì‚¬ë¡€ì™€ ë¹„êµ/ëŒ€ì¡°í•˜ê±°ë‚˜, ì´ë¡ ì  ë°°ê²½, ë˜ëŠ” êµ­ë‚´ ë„ì… ë…¼ì˜ë¥¼ ìœ„í•œ ì°¸ê³  ìë£Œë¡œì„œ ë°˜ë“œì‹œ ëª©ì°¨ì— í¬í•¨ì‹œì¼œì£¼ì„¸ìš”. ì–´ë–¤ ì •ë³´ë„ ëˆ„ë½í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
3.  **ìµœì¢… ëª©í‘œ:** ìµœì¢…ì ìœ¼ë¡œ ì´ ë³´ê³ ì„œëŠ” í•œêµ­ì— ì‚¬ë‚´ ë³€í˜¸ì‚¬ ACPë¥¼ ë„ì…í•˜ê¸° ìœ„í•œ ë²•ì , ì •ì±…ì  ì‹œì‚¬ì ì„ ë„ì¶œí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

ìœ„ ì§€ì‹œì‚¬í•­ì— ë”°ë¼, ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ë³´ê³ ì„œ ëª©ì°¨(ê°œìš”)ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.
ì„œë¡ , ë³¸ë¡ (ìœ ëŸ½ ì‚¬ë¡€ ì¤‘ì‹¬ì˜ ì—¬ëŸ¬ ì¥ê³¼ ì ˆ í¬í•¨), ê²°ë¡ (êµ­ë‚´ ë„ì…ì„ ìœ„í•œ ì œì–¸)ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

--- í†µí•© ë¬¸ì„œ ë‚´ìš© ---
{content}
"""

# =============================================================================
# ê¸°ì¡´ í•¨ìˆ˜ë“¤
# =============================================================================


def get_model_for_task(task_name):
    """
    íŠ¹ì • ì‘ì—…ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    model_name = MODELS.get(task_name, "gemini-1.5-flash")  # ê¸°ë³¸ê°’
    print(f"[{task_name}] ëª¨ë¸: {model_name}")

    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
    return genai.GenerativeModel(model_name)


def configure_genai():
    """API í‚¤ë¥¼ ë¡œë“œí•˜ê³  genaië¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def generate_content(model, prompt):
    """
    ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def print_model_configuration():
    """
    í˜„ì¬ ëª¨ë¸ ì„¤ì •ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    mode = "í”„ë¡œë•ì…˜" if USE_PRODUCTION_MODELS else "í…ŒìŠ¤íŠ¸"
    print(f"\n=== ëª¨ë¸ ì„¤ì • ({mode} ëª¨ë“œ) ===")
    for task, model in MODELS.items():
        budget = THINKING_BUDGETS.get(task)
        budget_str = (
            f" (Thinking Budget: {budget})"
            if budget is not None
            else " (Thinking Budget: ê¸°ë³¸ê°’)"
        )
        print(f"  {task}: {model}{budget_str}")
    print("=" * 50)


def read_all_source_files(source_dir="sources"):
    """
    source_dir ë‚´ì˜ ëª¨ë“  .md íŒŒì¼ ë‚´ìš©ì„ ì½ì–´ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
    ê° íŒŒì¼ ë‚´ìš© ì‚¬ì´ì—ëŠ” êµ¬ë¶„ì„ ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    all_content = []
    try:
        file_names = [f for f in os.listdir(source_dir) if f.endswith(".md")]
        print(f"ì´ {len(file_names)}ê°œì˜ íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.")

        for file_name in sorted(file_names):  # ì¼ê´€ëœ ìˆœì„œë¥¼ ìœ„í•´ ì •ë ¬
            file_path = os.path.join(source_dir, file_name)
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                all_content.append(
                    f"--- ë¬¸ì„œ ì‹œì‘: {file_name} ---\n\n{content}\n\n--- ë¬¸ì„œ ë: {file_name} ---\n\n"
                )

        print("ëª¨ë“  íŒŒì¼ ë‚´ìš©ì„ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤.")
        return "\n".join(all_content)

    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{source_dir}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None


def extract_and_consolidate_references(content):
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì†ŒìŠ¤ ì½˜í…ì¸ ì—ì„œ ê°ì£¼ì™€ ì°¸ê³ ë¬¸í—Œì„ ì¶”ì¶œí•˜ê³  í†µí•©í•©ë‹ˆë‹¤.
    AIê°€ ë” ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ JSON ëŒ€ì‹  ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print("\nì°¸ê³ ë¬¸í—Œ ë° ê°ì£¼ ì¶”ì¶œ ë° í†µí•© ì‹œì‘...")

    model = get_model_for_task("reference_extraction")
    ai_extracted_data = None
    last_response = ""
    last_error = None

    for attempt in range(3):  # ìµœëŒ€ 3ë²ˆ ì‹œë„
        print(f"AI ê¸°ë°˜ ì¶”ì¶œ ì‹œë„ ({attempt + 1}/3)...")

        prompt = ""
        if last_error:
            prompt = f"""
            ì´ì „ ì‹œë„ì—ì„œ ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {last_error}
            ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ìœ íš¨í•œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

            --- ì˜¤ë¥˜ ë°œìƒ í…ìŠ¤íŠ¸ ---
            {last_response}
            --- ë ---
            
            **ì¶œë ¥ í˜•ì‹ (ì˜¤ì§ ì•„ë˜ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ë§Œ ì¶œë ¥):**
            ## ê°ì£¼
            [1] ê°ì£¼ ë‚´ìš© 1
            
            ---
            
            ## ì°¸ê³ ë¬¸í—Œ
            - ì°¸ê³ ë¬¸í—Œ 1 (ì¶œì²˜)
            """
        else:
            prompt = f"""
            ë‹¹ì‹ ì€ ë²•ë¥  ë³´ê³ ì„œì˜ ì°¸ê³ ë¬¸í—Œì„ ì „ë¬¸ì ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” AIì…ë‹ˆë‹¤.
            ì•„ë˜ í†µí•© ë¬¸ì„œì—ì„œ 'ì°¸ê³ ë¬¸í—Œ' ì„¹ì…˜ë§Œ ì‹ë³„í•˜ê³ , ê·¸ ì•ˆì˜ ì¶œì²˜ ëª©ë¡ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ê°ì£¼ ì •ë³´ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤.

            **ì •ì˜:**
            - **ì°¸ê³ ë¬¸í—Œ (Bibliography/References):** ë³´ê³ ì„œ ì‘ì„±ì— ì‚¬ìš©ëœ ìë£Œì˜ ì¶œì²˜ ëª©ë¡ì…ë‹ˆë‹¤. 'ì°¸ê³ ë¬¸í—Œ', 'References', 'ì°¸ê³  ìë£Œ', 'Bibliography' ë“± ë‹¤ì–‘í•œ ì œëª©ìœ¼ë¡œ ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

            --- í†µí•© ë¬¸ì„œ ì‹œì‘ ---
            {content}
            --- í†µí•© ë¬¸ì„œ ë ---

            **ì‘ì—… ìš”ì²­:**
            1.  'ì°¸ê³ ë¬¸í—Œ', 'References', 'ì°¸ê³  ìë£Œ' ë“±ê³¼ ê°™ì€ ì œëª© ì•„ë˜ ìˆëŠ” ëª¨ë“  ì¶œì²˜ ëª©ë¡ì„ ì°¾ì•„ì„œ ëª©ë¡ìœ¼ë¡œ ë§Œë“œì„¸ìš”. **ì„¤ëª… ë‚´ìš©ì´ ì•„ë‹Œ, ì¶œì²˜ ìì²´ë¥¼ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.**
            2.  ì•„ë˜ ì§€ì •ëœ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì— ë§ì¶° **ì°¸ê³ ë¬¸í—Œ**ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

            **ì¶œë ¥ í˜•ì‹ (ì˜¤ì§ ë§ˆí¬ë‹¤ìš´ë§Œ ì¶œë ¥):**
            ## ì°¸ê³ ë¬¸í—Œ

            - ì¶œì²˜ 1 (ì˜ˆ: OOO ì €, "ë…¼ë¬¸ ì œëª©", 2023)
            - ì¶œì²˜ 2 (ì˜ˆ: https://example.com/article)
            """

        response_text = generate_content(model, prompt)
        last_response = response_text

        if not response_text:
            last_error = "AI ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            continue

        try:
            footnotes = {}
            references = []

            # ê°ì£¼ì™€ ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ì„ ë¶„ë¦¬
            parts = response_text.split("---")
            footnote_part = ""
            reference_part = ""

            if len(parts) >= 2:
                footnote_part = parts[0]
                reference_part = parts[1]
            elif "## ê°ì£¼" in response_text:
                footnote_part = (
                    response_text.split("## ì°¸ê³ ë¬¸í—Œ")[0]
                    if "## ì°¸ê³ ë¬¸í—Œ" in response_text
                    else response_text
                )
            elif "## ì°¸ê³ ë¬¸í—Œ" in response_text:
                reference_part = response_text

            # ê°ì£¼ íŒŒì‹±
            if "## ê°ì£¼" in footnote_part:
                fn_content = footnote_part.split("## ê°ì£¼")[1].strip()
                fn_matches = re.finditer(r"\[(\d+)\]\s*(.*)", fn_content)
                for match in fn_matches:
                    footnotes[int(match.group(1))] = match.group(2).strip()

            # ì°¸ê³ ë¬¸í—Œ íŒŒì‹±
            if "## ì°¸ê³ ë¬¸í—Œ" in reference_part:
                ref_content = reference_part.split("## ì°¸ê³ ë¬¸í—Œ")[1].strip()
                references = [
                    line.strip().lstrip("- ").strip()
                    for line in ref_content.split("\n")
                    if line.strip()
                ]

            if not footnotes and not references:
                raise ValueError("AI ì‘ë‹µì—ì„œ ê°ì£¼ë‚˜ ì°¸ê³ ë¬¸í—Œì„ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # ì°¸ê³ ë¬¸í—Œì— ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            final_references = {
                i + 1: ref for i, ref in enumerate(sorted(list(set(references))))
            }

            ai_extracted_data = {"footnotes": footnotes, "references": final_references}
            print("AI ê¸°ë°˜ ì¶”ì¶œ ë° íŒŒì‹± ì„±ê³µ.")
            break
        except Exception as e:
            print(f"AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            last_error = str(e)
            ai_extracted_data = None

    if not ai_extracted_data:
        print("AIë¥¼ í†µí•œ ì¶”ì¶œì— ìµœì¢… ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¹ˆ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return {"footnotes": {}, "references": {}}

    print(
        f"ê°ì£¼ {len(ai_extracted_data['footnotes'])}ê°œ, ì°¸ê³ ë¬¸í—Œ {len(ai_extracted_data['references'])}ê°œ ì¶”ì¶œ ì™„ë£Œ"
    )
    return ai_extracted_data


def analyze_content_overlap(content):
    """
    ì½˜í…ì¸ ì˜ ì¤‘ë³µ ë¶€ë¶„ì„ ë¶„ì„í•˜ê³  í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    print("\nì½˜í…ì¸  ì¤‘ë³µ ë¶„ì„ ì‹œì‘...")
    model = get_model_for_task("content_analysis")

    prompt = f"""
    ì•„ë˜ëŠ” ì—¬ëŸ¬ ë¬¸ì„œì˜ ë‚´ìš©ì„ í•©ì¹œ í†µí•© ë¬¸ì„œì…ë‹ˆë‹¤.
    --- í†µí•© ë¬¸ì„œ ì‹œì‘ ---
    {content}
    --- í†µí•© ë¬¸ì„œ ë ---
    
    **ë¶„ì„ ìš”ì²­ì‚¬í•­:**
    ìœ„ í†µí•© ë¬¸ì„œ ë‚´ìš© ì „ì²´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¶„ì„í•˜ê³  ì¶”ì¶œí•´ì£¼ì„¸ìš”.
    1. ì—¬ëŸ¬ ë¬¸ì„œì— ê±¸ì³ ì¤‘ë³µì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ì£¼ì œ ë˜ëŠ” ë‚´ìš©ì„ ì‹ë³„í•´ì£¼ì„¸ìš”.
    2. ê° ë¬¸ì„œë§Œì´ ê°€ì§€ê³  ìˆëŠ” ê³ ìœ í•œ ì •ë³´ë‚˜ ê´€ì ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
    3. ì •ë³´ì˜ ì¤‘ìš”ë„ì™€ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•˜ì—¬, ë³´ê³ ì„œ ì‘ì„± ì‹œ ìš°ì„ ì ìœ¼ë¡œ ë°˜ì˜í•´ì•¼ í•  í•µì‹¬ ì •ë³´ë¥¼ ì„ ë³„í•´ì£¼ì„¸ìš”.
    4. í˜„ì¬ ì •ë³´ì—ì„œ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ë” ë³´ê°•ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ 'ì½˜í…ì¸  ê°­'ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
    
    **ì¶œë ¥ í˜•ì‹:**
    ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ì— ë§ì¶°ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
    ```json
    {{
        "duplicate_topics": ["ì¤‘ë³µ ì£¼ì œ1", "ì¤‘ë³µ ì£¼ì œ2"],
        "unique_insights": ["ê³ ìœ  ì¸ì‚¬ì´íŠ¸1", "ê³ ìœ  ì¸ì‚¬ì´íŠ¸2"],
        "priority_information": ["ìš°ì„ ìˆœìœ„ ì •ë³´1", "ìš°ì„ ìˆœìœ„ ì •ë³´2"],
        "content_gaps": ["ëˆ„ë½ëœ ì •ë³´1", "ëˆ„ë½ëœ ì •ë³´2"]
    }}
    ```
    """

    try:
        response_text = generate_content(model, prompt)
        if not response_text:
            return {}

        json_text = response_text.strip()
        if json_text.startswith("```json"):
            json_text = json_text[7:-3]
        elif json_text.startswith("```"):
            json_text = json_text[3:-3]

        analysis_data = json.loads(json_text)
        print("ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ")
        return analysis_data
    except Exception as e:
        print(f"ì½˜í…ì¸  ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}


def generate_outline(content):
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸ ì˜ ê°œìš”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print("\nLLMì—ê²Œ ë³´ê³ ì„œ ê°œìš” ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤...")
    try:
        configure_genai()
        model = get_model_for_task("outline_generation")

        # ê¸€ë¡œë²Œ í…œí”Œë¦¿ì— í†µí•© ë¬¸ì„œ ë‚´ìš©ì„ ì‚½ì…
        prompt = OUTLINE_PROMPT_TEMPLATE.format(content=content)

        response_text = generate_content(model, prompt)
        print("ê°œìš” ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
        return response_text

    except Exception as e:
        print(f"LLM ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def generate_draft_report(outline, full_content):
    """ê°œìš”ì™€ ì „ì²´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("\n\n--- ë³´ê³ ì„œ ì´ˆì•ˆ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤ ---")
    model = get_model_for_task("draft_generation")

    prompt = f"""
    ë‹¹ì‹ ì€ ë²•ë¥  ë³´ê³ ì„œ ì „ë¬¸ ì‘ì„±ìì…ë‹ˆë‹¤. ì£¼ì–´ì§„ 'ê°œìš”'ì™€ 'ì „ì²´ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, ìƒì„¸í•˜ê³  ê¸´ ë³´ê³ ì„œ ë³¸ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    **âš ï¸ ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­ (ë°˜ë“œì‹œ ì¤€ìˆ˜):**
    1.  **ìµœì†Œ ë¶„ëŸ‰:** í•œêµ­ì–´ ê¸°ì¤€ ìµœì†Œ 20,000ì ì´ìƒ, 8,000ë‹¨ì–´ ì´ìƒì´ ë˜ë„ë¡ ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    2.  **ê°œìš” ì™„ì „ ì¤€ìˆ˜:** 'ê°œìš”'ì˜ ëª¨ë“  ì¥Â·ì ˆì„ ë¹ ì§ì—†ì´ ì‘ì„±í•˜ê³ , ê° ì ˆë§ˆë‹¤ ìµœì†Œ 5-10ê°œ ë¬¸ë‹¨ìœ¼ë¡œ ì¶©ë¶„íˆ ì„œìˆ í•˜ì„¸ìš”.
    3.  **ì‹¬ì¸µ ë¶„ì„:** ë‹¨ìˆœí•œ ì‚¬ì‹¤ ë‚˜ì—´ì´ ì•„ë‹Œ, ê¹Šì´ ìˆëŠ” ë¶„ì„ê³¼ ë…¼ì¦ì„ í¬í•¨í•˜ì„¸ìš”.
    4.  **êµ¬ì²´ì  ì‚¬ë¡€:** ê° êµ­ê°€ë³„ ì‚¬ë¡€, íŒë¡€, ë²•ì¡°ë¬¸ ë“±ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
    5.  **ë¹„êµ ë¶„ì„:** êµ­ê°€ ê°„ ì œë„ ë¹„êµ, ì¥ë‹¨ì  ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”.

    **ì§€ì‹œì‚¬í•­:**
    - **ëª©ì°¨ ìƒì„± ê¸ˆì§€:** ëª©ì°¨ë‚˜ TOCëŠ” ì‘ì„±í•˜ì§€ ë§ê³ , ë°”ë¡œ ë³¸ë¬¸ ë‚´ìš©ë¶€í„° ì‹œì‘í•˜ì„¸ìš”.
    - **ê°ì£¼ ì‚¬ìš© ê¸ˆì§€:** ê°ì£¼ ëŒ€ì‹  ë³¸ë¬¸ì— ê´„í˜¸ë‚˜ ë¬¸ì¥ìœ¼ë¡œ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”.
    - **ì°¸ê³ ë¬¸í—Œ í¬í•¨ ê¸ˆì§€:** ì°¸ê³ ë¬¸í—Œ ëª©ë¡ì€ ë³„ë„ë¡œ ì¶”ê°€ë  ì˜ˆì •ì´ë¯€ë¡œ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    - **ì™„ì „í•œ ë¬¸ì„œ:** ì„œë¡ ë¶€í„° ê²°ë¡ ê¹Œì§€ ì™„ì „í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    **ë¶„ëŸ‰ ê²€ì¦:** ì‘ì„± í›„ ë‚´ìš©ì´ ìµœì†Œ 20,000ìê°€ ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ë¶€ì¡±í•˜ë©´ ê° ì„¹ì…˜ì„ ë” ìì„¸íˆ í™•ì¥í•˜ì„¸ìš”.

    --- ì „ì²´ ë‚´ìš© (ì°¸ê³  ìë£Œ) ---
    {full_content}
    --- ë ---

    --- ì‘ì„±í•  ë³´ê³ ì„œ ê°œìš” ---
    {outline}
    --- ë ---

    ì´ì œ ìœ„ ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ìƒì„¸í•˜ê³  ê¸´ ë³´ê³ ì„œ ë³¸ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    generation_config = {
        "temperature": 0.7,
        "top_p": 0.95,
        "top_k": 40,
        "max_output_tokens": 8192,  # ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜ ì¦ê°€
    }

    draft = model.generate_content(prompt, generation_config=generation_config).text

    # ìƒì„±ëœ ì´ˆì•ˆì˜ ê¸¸ì´ í™•ì¸
    char_count = len(draft)
    word_count = len(draft.split())
    print(f"ìƒì„±ëœ ì´ˆì•ˆ ê¸¸ì´: {char_count:,}ì, {word_count:,}ë‹¨ì–´")

    if char_count < 10000:
        print(
            "âš ï¸ ê²½ê³ : ìƒì„±ëœ ì´ˆì•ˆì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ê¸´ ë‚´ìš©ì„ ìƒì„±í•˜ë„ë¡ ì¬ì‹œë„í•©ë‹ˆë‹¤."
        )
        # ì¬ì‹œë„ í”„ë¡¬í”„íŠ¸
        retry_prompt = f"""
        ì´ì „ì— ìƒì„±í•œ ì´ˆì•ˆì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({char_count:,}ì).
        ë‹¤ì‹œ í•œ ë²ˆ ìµœì†Œ 20,000ì ì´ìƒì˜ ë§¤ìš° ìƒì„¸í•˜ê³  ê¸´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ê° ì„¹ì…˜ë§ˆë‹¤ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
        - ìƒì„¸í•œ ë°°ê²½ ì„¤ëª…
        - êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ì˜ˆì‹œ
        - ë¹„êµ ë¶„ì„
        - ë²•ì  ë…¼ì¦
        - ì‹œì‚¬ì ê³¼ í•¨ì˜
        
        --- ì´ì „ ì´ˆì•ˆ ---
        {draft}
        --- ë ---
        
        ìœ„ ì´ˆì•ˆì„ ê¸°ë°˜ìœ¼ë¡œ ê° ì„¹ì…˜ì„ 3-5ë°° í™•ì¥í•˜ì—¬ ë§¤ìš° ìƒì„¸í•˜ê³  ê¸´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        extended_draft = model.generate_content(
            retry_prompt, generation_config=generation_config
        ).text
        if len(extended_draft) > len(draft):
            draft = extended_draft
            print(f"í™•ì¥ëœ ì´ˆì•ˆ ê¸¸ì´: {len(draft):,}ì, {len(draft.split()):,}ë‹¨ì–´")

    print("ë³´ê³ ì„œ ì´ˆì•ˆ ìƒì„± ì™„ë£Œ.")
    return draft


def editorial_review(draft, full_content, references_data):
    """
    í¸ì§‘ì¥ AIê°€ ì´ˆì•ˆì„ ê²€í† í•˜ê³  ê°œì„ í•©ë‹ˆë‹¤.
    """
    print("\ní¸ì§‘ì¥ AI ê²€í†  ì‹œì‘...")
    model = get_model_for_task("editorial_review")

    prompt = f"""
    ë‹¹ì‹ ì€ ë²•ë¥  ë³´ê³ ì„œ ì „ë¬¸ í¸ì§‘ì¥ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì•„ë˜ 'ê²€í† í•  ì´ˆì•ˆ'ì„ 'ì›ë³¸ ìë£Œ'ì™€ 'ì°¸ê³ ë¬¸í—Œ ë°ì´í„°'ë¥¼ ì°¸ê³ í•˜ì—¬ ìˆ˜ì •Â·ê°œì„ í•´ ì™„ì„±ëœ ë³´ê³ ì„œ ë³¸ë¬¸ì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.

    **ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™: ì¶œë ¥ì€ ì˜¤ì§ ìµœì¢…ì ìœ¼ë¡œ ì™„ì„±ëœ ë³´ê³ ì„œì˜ ë³¸ë¬¸ ë‚´ìš©ì´ì–´ì•¼ í•©ë‹ˆë‹¤.**
    ì ˆëŒ€ë¡œ ê²€í†  ì˜ê²¬, ìˆ˜ì • ê³¼ì •, ì›ë³¸ê³¼ì˜ ë¹„êµ, ë˜ëŠ” ê°ì£¼Â·ì°¸ê³ ë¬¸í—Œ ëª©ë¡ ë“± ê¸°íƒ€ ë¶€ì—° ì„¤ëª…ì„ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.
    ê°ì£¼ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì›ë³¸ ê°ì£¼ì— í¬í•¨ëœ ì •ë³´ê°€ í•„ìš”í•˜ë‹¤ë©´ ë³¸ë¬¸ ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì£¼ì„¸ìš”.
    
    --- ì›ë³¸ ìë£Œ (ì „ì²´ ë‚´ìš©) ---
    {full_content}
    --- ë ---
    
    --- ì°¸ê³ ë¬¸í—Œ ë°ì´í„° ---
    {json.dumps(references_data.get('references', {}), ensure_ascii=False, indent=2)}
    --- ë ---

    --- ê²€í† í•  ì´ˆì•ˆ ---
    {draft}
    --- ë ---

    **ê°œì„  ì§€ì‹œì‚¬í•­:**
    1.  **ë…¼ë¦¬ì  íë¦„ ë° ì¼ê´€ì„±:** ì „ì²´ì ì¸ ë…¼ë¦¬ê°€ ëª…í™•í•˜ê³ , ìš©ì–´ë‚˜ ì£¼ì¥ì´ ì¼ê´€ë˜ë„ë¡ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”.
    2.  **ë‚´ìš© ì¤‘ë³µ ì²˜ë¦¬:** ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ê°€ì¥ í¬ê´„ì ì´ê³  ì •í™•í•œ ë²„ì „ìœ¼ë¡œ í†µí•©í•˜ë˜, ì •ë³´ê°€ ì†Œì‹¤ë˜ì§€ ì•Šë„ë¡ ì‹ ì¤‘í•˜ê²Œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.
    3.  **ì •ë³´ ë³´ê°• ë° ì‹¬ì¸µ ë¶„ì„:** 'ê²€í† í•  ì´ˆì•ˆ'ì˜ ë‚´ìš©ì´ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´, 'ì›ë³¸ ìë£Œ'ë¥¼ ì°¸ê³ í•˜ì—¬ ì ê·¹ì ìœ¼ë¡œ ë‚´ìš©ì„ í™•ì¥í•˜ê³  ë³´ê°•í•´ì£¼ì„¸ìš”. ë‹¨ìˆœ ì‚¬ì‹¤ ë‚˜ì—´ì„ ë„˜ì–´, ì„¤ë“ë ¥ ìˆëŠ” ë…¼ì¦ê³¼ ê¹Šì´ ìˆëŠ” ë¶„ì„ì´ ë˜ë„ë¡ ë¬¸ì²´ë¥¼ ê°•í™”í•´ì£¼ì„¸ìš”.
    4.  **í‘œí˜„ ë° ê°€ë…ì„±:** ì „ë¬¸ì ì¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë˜, ë…ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ëª…í™•í•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”.

    **ìµœì¢… ì¶œë ¥ë¬¼ì€ ë°˜ë“œì‹œ ë³´ê³ ì„œ ì œëª©ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•˜ë©°, ì˜¤ì§ ì™„ì„±ëœ ë³´ê³ ì„œ ë³¸ë¬¸ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì–´ë–¤ ë‚´ìš©ë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**
    
    **ì¶œë ¥ í˜•ì‹:**
    # ì‚¬ë‚´ ë³€í˜¸ì‚¬ë¥¼ ìœ„í•œ ACPì˜ êµ­ë‚´ ë„ì…ì„ ìœ„í•œ ìœ ëŸ½ ì‚¬ë¡€ ì—°êµ¬ì¡°ì‚¬

    [ì—¬ê¸°ì— ë³´ê³ ì„œ ë³¸ë¬¸ ë‚´ìš©ì„ ì‘ì„±]
    """

    generation_config = {"temperature": 0.7, "top_p": 0.95, "top_k": 40}

    response = model.generate_content(prompt, generation_config=generation_config).text

    # AIê°€ ì§€ì‹œë¥¼ ì–´ê¸°ê³  êµ¬ë¶„ìë‚˜ ë©”íƒ€ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°ë¥¼ ì²˜ë¦¬
    final_report = response.strip()

    # ì œëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ë³¸ë¬¸ ì‹œì‘ ë¶€ë¶„ ì°¾ê¸°
    title_str = "ì‚¬ë‚´ ë³€í˜¸ì‚¬ë¥¼ ìœ„í•œ ACPì˜ êµ­ë‚´ ë„ì…ì„ ìœ„í•œ ìœ ëŸ½ ì‚¬ë¡€ ì—°êµ¬ì¡°ì‚¬"

    # ì œëª©ì´ ì—¬ëŸ¬ ë²ˆ ë‚˜íƒ€ë‚˜ëŠ” ê²½ìš° ì²« ë²ˆì§¸ ì œëª©ë§Œ ì‚¬ìš©
    title_positions = []
    start_pos = 0
    while True:
        pos = final_report.find(title_str, start_pos)
        if pos == -1:
            break
        title_positions.append(pos)
        start_pos = pos + len(title_str)

    if title_positions:
        # ì²« ë²ˆì§¸ ì œëª©ë¶€í„° ì‹œì‘
        final_report = final_report[title_positions[0] :]

        # ë§Œì•½ ì œëª©ì´ ì¤‘ë³µìœ¼ë¡œ ë‚˜íƒ€ë‚˜ë©´ ì²« ë²ˆì§¸ ì œëª© ì´í›„ ë‘ ë²ˆì§¸ ì œëª© ì „ê¹Œì§€ë§Œ ì‚¬ìš©
        if len(title_positions) > 1:
            second_title_pos = title_positions[1] - title_positions[0]
            final_report = final_report[:second_title_pos]

    # "---" êµ¬ë¶„ì ë’¤ì˜ ë‚´ìš©ì€ ì œê±°í•˜ì—¬ ë³¸ë¬¸ë§Œ ë‚¨ê¸°ê¸°
    if "---" in final_report:
        final_report = final_report.split("---")[0].strip()

    # ìµœì†Œí•œì˜ ë‚´ìš© ê²€ì¦
    if len(final_report.split()) < 100:  # ë‹¨ì–´ ìˆ˜ê°€ ë„ˆë¬´ ì ì€ ê²½ìš°
        print("ê²½ê³ : ìƒì„±ëœ ë³´ê³ ì„œ ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì´ˆì•ˆì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        final_report = draft

    print("í¸ì§‘ì¥ AI ê²€í†  ì™„ë£Œ.")
    return final_report


def final_quality_check(report, outline, references_data):
    """
    ìµœì¢… í’ˆì§ˆ ê²€ì‚¬ ë° ì‚¬ì‹¤ í™•ì¸
    """
    print("\nìµœì¢… í’ˆì§ˆ ê²€ì‚¬ ì‹œì‘...")
    model = get_model_for_task("quality_check")

    prompt = f"""
    ë‹¹ì‹ ì€ ìµœì¢… í’ˆì§ˆ ê²€ì‚¬ê´€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µë˜ëŠ” ìë£Œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œì˜ ìµœì¢… í’ˆì§ˆì„ ê²€ì‚¬í•˜ê³ , ê²€í†  ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    --- ì›ë³¸ ê°œìš” ---
    {outline}
    --- ë ---

    --- ì°¸ê³ ë¬¸í—Œ ë°ì´í„° ---
    {json.dumps(references_data.get('references', {}), ensure_ascii=False, indent=2)}
    --- ë ---

    --- ìµœì¢… ê²€í† í•  ë³´ê³ ì„œ ---
    {report}
    --- ë ---
    
    **ê²€í†  ì§€ì‹œì‚¬í•­:**
    ìœ„ ìë£Œë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ 'ìµœì¢… ê²€í† í•  ë³´ê³ ì„œ'ë¥¼ ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ê²€í† í•˜ê³ , ê° í•­ëª©ë³„ë¡œ êµ¬ì²´ì ì¸ ê²€í†  ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    1.  **ê°œìš” ì¼ì¹˜ì„±:** ë³´ê³ ì„œì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì´ 'ì›ë³¸ ê°œìš”'ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€í† í•´ì£¼ì„¸ìš”.
    2.  **ì°¸ê³ ë¬¸í—Œ ì—°ê²°ì„±:** ë³¸ë¬¸ì´ ì°¸ê³ ë¬¸í—Œ ëª©ë¡ì— ì ì ˆíˆ ê·¼ê±°ë¥¼ í‘œì‹œí•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ê°ì£¼ ì‚¬ìš© ì—¬ë¶€ëŠ” ë¬´ì‹œí•˜ê³ , ë‚´ìš©ê³¼ ì¶œì²˜ì˜ ë§¤ì¹­ì„ í‰ê°€í•´ì£¼ì„¸ìš”.
    3.  **ì •ë³´ ì •í™•ì„±:** êµ­ê°€ë³„ ì •ë³´ ë“± ì‚¬ì‹¤ ê´€ê³„ì— ì˜¤ë¥˜ê°€ ì—†ëŠ”ì§€ ê²€í† í•´ì£¼ì„¸ìš”.
    4.  **ì¼ê´€ì„±:** ìš©ì–´ë‚˜ ì£¼ì¥ì´ ë³´ê³ ì„œ ì „ë°˜ì— ê±¸ì³ ì¼ê´€ë˜ê²Œ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.

    **ì¶œë ¥ í˜•ì‹:**
    # í’ˆì§ˆ ê²€ì‚¬ ë³´ê³ ì„œ

    ## 1. ê°œìš” ì¼ì¹˜ì„±
    - ë°œê²¬ëœ ë¬¸ì œì :
    - ê°œì„  ì œì•ˆ:

    ## 2. ì°¸ê³ ë¬¸í—Œ ì—°ê²°ì„±
    - ë°œê²¬ëœ ë¬¸ì œì :
    - ê°œì„  ì œì•ˆ:

    [ì´í•˜ ê° í•­ëª©ë³„ë¡œ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±]
    """

    try:
        review_comments = generate_content(model, prompt)
        print("ìµœì¢… í’ˆì§ˆ ê²€ì‚¬ ì™„ë£Œ")
        return report, (
            review_comments
            if review_comments
            else (report, "í’ˆì§ˆ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        )
    except Exception as e:
        print(f"ìµœì¢… í’ˆì§ˆ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return (
            report,
            f"í’ˆì§ˆ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
        )  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ê³¼ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜


def format_references_for_report(references_data):
    """
    ì¶”ì¶œëœ ê°ì£¼ì™€ ì°¸ê³ ë¬¸í—Œ ë°ì´í„°ë¥¼ ë³´ê³ ì„œì— ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    markdown_text = ""

    # ì°¸ê³ ë¬¸í—Œ í¬ë§· (ì„¤ëª…ì´ ì•„ë‹Œ ì¶œì²˜ ëª©ë¡)
    if references_data.get("references"):
        markdown_text += "\n\n---\n\n## ì°¸ê³ ë¬¸í—Œ\n\n"
        try:
            # í‚¤(ì°¸ê³ ë¬¸í—Œ ë²ˆí˜¸)ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ì •ë ¬
            sorted_references = sorted(
                references_data["references"].items(), key=lambda item: int(item[0])
            )
            for number, text in sorted_references:
                markdown_text += f"{number}. {text}\n"
        except (ValueError, TypeError) as e:
            print(f"ì°¸ê³ ë¬¸í—Œ ì •ë ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            for number, text in references_data["references"].items():
                markdown_text += f"{number}. {text}\n"

    return markdown_text


def generate_enhanced_report(draft_report, outline, full_content, references_data):
    """ì£¼ì–´ì§„ ì´ˆì•ˆì„ ê¸°ë°˜ìœ¼ë¡œ í¸ì§‘ì¥ ê²€í†  â†’ ì°¸ê³ ìë£Œ ì‚½ì… â†’ í’ˆì§ˆ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""

    # 5-1ë‹¨ê³„: í¸ì§‘ì¥ AI ê²€í† 
    print("\n5-1ë‹¨ê³„: í¸ì§‘ì¥ AI ê²€í† ")
    reviewed_report = editorial_review(draft_report, full_content, references_data)
    if not reviewed_report:
        print("ê²½ê³ : í¸ì§‘ì¥ ê²€í† ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì´ˆì•ˆì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        reviewed_report = draft_report

    # 5-2ë‹¨ê³„: ê°ì£¼ ë° ì°¸ê³ ë¬¸í—Œ ì¶”ê°€
    print("\n5-2ë‹¨ê³„: ê°ì£¼ ë° ì°¸ê³ ë¬¸í—Œ ì¶”ê°€")
    references_markdown = format_references_for_report(references_data)

    # ë³¸ë¬¸ê³¼ ì°¸ê³ ìë£Œë¥¼ êµ¬ë¶„í•˜ëŠ” êµ¬ë¶„ì„  ì¶”ê°€
    report_with_references = f"{reviewed_report}\n\n{'=' * 80}\n\n{references_markdown}"

    # 5-3ë‹¨ê³„: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬
    print("\n5-3ë‹¨ê³„: ìµœì¢… í’ˆì§ˆ ê²€ì‚¬")
    final_report, quality_check_report = final_quality_check(
        report_with_references, outline, references_data
    )

    # ìµœì¢… ê²€ì¦ â€“ ì´ˆì•ˆì´ ì¶©ë¶„íˆ ê¸¸ì§€ ì•Šìœ¼ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼
    if len(reviewed_report.split()) < 100:
        print("ê²½ê³ : ìµœì¢… ë³´ê³ ì„œ ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
        return None, "ë³´ê³ ì„œ ë³¸ë¬¸ ìƒì„± ì‹¤íŒ¨"

    return final_report, quality_check_report


def add_generation_info(quality_check_report, generation_info):
    """
    ìƒì„± ê³¼ì •ì˜ ë©”íƒ€ë°ì´í„°ì™€ í’ˆì§ˆ ê²€ì‚¬ ë³´ê³ ì„œë¥¼ ê²°í•©í•©ë‹ˆë‹¤.
    """
    metadata = {
        "generation_date": datetime.now().isoformat(),
        "source_files": generation_info.get("source_files", []),
        "total_references": len(generation_info.get("references", [])),
        "models_used": MODELS,
        "generation_stages": ["outline", "draft", "editorial_review", "quality_check"],
        "production_mode": USE_PRODUCTION_MODELS,
    }

    info_section = f"""# ë³´ê³ ì„œ ìƒì„± ì •ë³´

- **ìƒì„± ì¼ì‹œ:** {metadata['generation_date']}
- **ì‚¬ìš© ëª¨ë¸:** {'í”„ë¡œë•ì…˜ ëª¨ë“œ' if metadata['production_mode'] else 'í…ŒìŠ¤íŠ¸ ëª¨ë“œ'}
- **ìƒì„± ë‹¨ê³„:** {' â†’ '.join(metadata['generation_stages'])}
- **ì°¸ê³ ë¬¸í—Œ ìˆ˜:** {metadata['total_references']}ê°œ

## ëª¨ë¸ ìƒì„¸ ì •ë³´
"""

    for task, model in metadata["models_used"].items():
        info_section += f"- **{task}:** {model}\n"

    info_section += f"""
---

# ìµœì¢… í’ˆì§ˆ ê²€ì‚¬ ë³´ê³ ì„œ

{quality_check_report}
"""
    return info_section


def get_unique_filename(base_name, date_str, extension=".md"):
    """
    ë‚ ì§œì™€ ì‹œê°„ì„ í¬í•¨í•œ ê³ ìœ í•œ íŒŒì¼ ì´ë¦„ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë²ˆí˜¸ë¥¼ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    name_without_ext = os.path.splitext(base_name)[0]
    new_base = f"{name_without_ext}_{date_str}"

    counter = 1
    filename = f"{new_base}{extension}"

    while os.path.exists(filename):
        filename = f"{new_base}_{counter}{extension}"
        counter += 1

    return filename


def main():
    parser = argparse.ArgumentParser(description="ACP ë³´ê³ ì„œ ìƒì„± íŒŒì´í”„ë¼ì¸")
    parser.add_argument(
        "--step",
        choices=["draft", "enhance", "all"],
        default="all",
        help="draft: ì´ˆì•ˆë§Œ ìƒì„± / enhance: ê¸°ì¡´ ì´ˆì•ˆì„ í–¥ìƒ / all: í’€ íŒŒì´í”„ë¼ì¸",
    )
    parser.add_argument(
        "--draft-path",
        help="'enhance' ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ê¸°ì¡´ ì´ˆì•ˆ íŒŒì¼ ê²½ë¡œ",
    )

    args = parser.parse_args()

    # ëª¨ë¸ ì„¤ì • ì •ë³´ ì¶œë ¥
    print_model_configuration()

    print("\n1ë‹¨ê³„: ì†ŒìŠ¤ íŒŒì¼ ì½ê¸°")
    combined_content = read_all_source_files()
    if not combined_content:
        print("ì†ŒìŠ¤ íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    try:
        configure_genai()
    except ValueError as e:
        print(e)
        return

    # 2ë‹¨ê³„: ì°¸ê³ ë¬¸í—Œ ì¶”ì¶œ (ëª¨ë“  ë‹¨ê³„ ê³µí†µ)
    print("\n2ë‹¨ê³„: ì°¸ê³ ë¬¸í—Œ ì¶”ì¶œ")
    references_data = extract_and_consolidate_references(combined_content)

    # 3ë‹¨ê³„: ê°œìš” ìƒì„± (draft, all ë‹¨ê³„ì—ì„œ í•„ìš”)
    outline = None
    if args.step in ["draft", "all", "enhance"]:
        print("\n3ë‹¨ê³„: ê°œìš” ìƒì„±")
        outline = generate_outline(combined_content)
        if not outline:
            print("ê°œìš” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return

    # draft ì „ìš© ì‹¤í–‰ --------------------------------------------------
    if args.step == "draft":
        print("\n4ë‹¨ê³„: ì´ˆì•ˆ ìƒì„±")
        draft_report = generate_draft_report(outline, combined_content)
        if not draft_report:
            print("ì´ˆì•ˆ ìƒì„± ì‹¤íŒ¨")
            return

        now = datetime.now()
        date_str = now.strftime("%Y%m%d_%H%M%S")
        draft_filename = get_unique_filename("draft_report", date_str)
        with open(draft_filename, "w", encoding="utf-8") as f:
            f.write(draft_report)
        print(f"ğŸ‰ ì´ˆì•ˆ ìƒì„± ì™„ë£Œ: {draft_filename}")
        return

    # enhance ì „ìš© ì‹¤í–‰ -----------------------------------------------
    if args.step == "enhance":
        if not args.draft_path or not os.path.exists(args.draft_path):
            print("--draft-path ì— ìœ íš¨í•œ ì´ˆì•ˆ íŒŒì¼ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
            return
        with open(args.draft_path, "r", encoding="utf-8") as f:
            draft_report = f.read()

        final_report, quality_check_report = generate_enhanced_report(
            draft_report, outline, combined_content, references_data
        )

        now = datetime.now()
        date_str = now.strftime("%Y%m%d_%H%M%S")
        report_filename = get_unique_filename("enhanced_report", date_str)
        with open(report_filename, "w", encoding="utf-8") as f:
            f.write(final_report)
        print(f"ğŸ‰ í–¥ìƒëœ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_filename}")
        return

    # all ë‹¨ê³„ (ê¸°ì¡´ ì „ì²´ íŒŒì´í”„ë¼ì¸) ---------------------------------
    print("\n4ë‹¨ê³„: ì´ˆì•ˆ ìƒì„±")
    draft_report = generate_draft_report(outline, combined_content)
    if not draft_report:
        print("ì´ˆì•ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    print("\n5ë‹¨ê³„: í–¥ìƒëœ ë³´ê³ ì„œ ìƒì„±")
    final_report, quality_check_report = generate_enhanced_report(
        draft_report, outline, combined_content, references_data
    )

    print("\n6ë‹¨ê³„: íŒŒì¼ ì €ì¥")
    now = datetime.now()
    date_str = now.strftime("%Y%m%d_%H%M%S")

    report_filename = get_unique_filename("enhanced_report", date_str)
    with open(report_filename, "w", encoding="utf-8") as f:
        f.write(final_report)

    info_filename = get_unique_filename("generation_info", date_str)
    with open(info_filename, "w", encoding="utf-8") as f:
        f.write(quality_check_report)

    print(f"ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {report_filename}")
    print(f"ğŸ“„ í’ˆì§ˆ ê²€ì‚¬ íŒŒì¼: {info_filename}")


if __name__ == "__main__":
    main()
